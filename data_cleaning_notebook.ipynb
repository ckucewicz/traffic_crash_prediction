{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530370af",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2723e49",
   "metadata": {},
   "source": [
    "With such a massive dataset, the cleaning process was both detailed and meticulous. Below, I provide a high-level overview of my general steps. More granular details, along with the specific justifications for my decisions, can be found within each corresponding section of this notebook.\n",
    "\n",
    "## Overview\n",
    "\n",
    "I cleaned each of the three datasets (crashes_df, people_df, and vehicles_df) with the primary goals of making the data more manageable and reducing noise by eliminating unnecessary features and handling null values.\n",
    "\n",
    "Throughout the cleaning process, I kept my target variable, most_severe_injury, in focus. Since most_severe_injury is a crash-level feature, the analysis in this project is centered around crash-level data. This distinction was especially important when working with people_df (person-level data) and vehicles_df (vehicle-level data), as merging these datasets with crashes_df required careful attention to avoid many-to-many relationships that could skew feature values. For instance, merging without proper aggregation could lead to inflated counts or inaccurate distributions of features such as the “number of injured persons per crash.” Without aggregation, a single crash with multiple people involved would be duplicated for each person in people_df, leading to an overrepresentation of crashes and skewed averages or totals. Proper aggregation ensures that each crash appears only once in the merged dataset\n",
    "\n",
    "To address this, I aggregated the cleaned people_df and vehicles_df into people_aggregated and vehicles_aggregated, respectively, before merging them with crashes_cleaned. This ensured a smooth merge process that maintained a one-to-one relationship with crash_record_id across the combined dataset.\n",
    "\n",
    "In order to simplify the analysis, I then adjusted the target variable (most_severe_injury) into a binary classification: serious injuries (fatalities and incapacitating injuries) versus non-serious injuries (minor or no injuries). This adjustment focused the modeling on predicting significant crash outcomes, providing a clearer and more manageable classification.\n",
    "\n",
    "The final merged dataset still contained over 600,000 records, which posed computational challenges. To address this, I employed stratified random sampling to create a representative subset of the data. This approach preserved the proportional distribution of classes in my target variable, most_severe_injury. To ensure reproducibility, I set a fixed random_state during sampling.\n",
    "\n",
    "The resulting stratified sample, ready for modeling, was uploaded to Kaggle to streamline reproducibility and accessibility for others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da066e20",
   "metadata": {},
   "source": [
    "## 1.0 Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dbd7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting data\n",
    "import os\n",
    "import zipfile\n",
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# for managing data\n",
    "import gc\n",
    "\n",
    "# for checking runtime\n",
    "import time\n",
    "\n",
    "# for data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# for feature selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3fc43a",
   "metadata": {},
   "source": [
    "### 1.1 Environment Setup and data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d89c0",
   "metadata": {},
   "source": [
    "For reproducibility purposes, the following code allows the user to download the data for this project from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6615fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install Kaggle API (if needed)\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa959793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: directory /root/.kaggle does not exist\n",
      "chmod: /root/.kaggle/kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Setup Kaggle credentials\n",
    "#os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "!cp kaggle.json /root/.kaggle/\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da79d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
      "Dataset URL: https://www.kaggle.com/datasets/ckucewicz/chicago-traffic-data\n",
      "License(s): apache-2.0\n",
      "Downloading chicago-traffic-data.zip to /Users/chriskucewicz/Documents/Flatiron/Phase5/phase5_capstone/traffic_crash_prediction\n",
      "100%|███████████████████████████████████████▉| 394M/394M [00:07<00:00, 52.4MB/s]\n",
      "100%|████████████████████████████████████████| 394M/394M [00:07<00:00, 55.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Download the dataset from Kaggle\n",
    "dataset_name = \"ckucewicz/chicago-traffic-data\"\n",
    "!kaggle datasets download -d {dataset_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdaec12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract the dataset\n",
    "zip_file = dataset_name.split('/')[-1] + \".zip\"\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e940c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chriskucewicz/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508: DtypeWarning: Columns (19,23,24,25,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/chriskucewicz/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508: DtypeWarning: Columns (31,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/chriskucewicz/anaconda3/envs/learn-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3508: DtypeWarning: Columns (20,39,40,41,43,47,48,49,52,54,57,58,60,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load CSV files into pandas DataFrames\n",
    "dataframes = {\n",
    "    'people': pd.read_csv('chicago_traffic_data/people.csv'),\n",
    "    'traffic_crashes': pd.read_csv('chicago_traffic_data/traffic_crashes.csv'),\n",
    "    'vehicles': pd.read_csv('chicago_traffic_data/vehicles.csv'),\n",
    "    'crashes_finalized': pd.read_csv('crashes_finalized_df.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dce4685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Access individual DataFrames\n",
    "people_df = dataframes['people']\n",
    "traffic_crashes_df = dataframes['traffic_crashes']\n",
    "vehicles_df = dataframes['vehicles']\n",
    "crashes_finalized_df = dataframes['crashes_finalized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3614dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people DataFrame:\n",
      "  PERSON_ID PERSON_TYPE                                    CRASH_RECORD_ID  \\\n",
      "0   O749947      DRIVER  81dc0de2ed92aa62baccab641fa377be7feb1cc47e6554...   \n",
      "\n",
      "   VEHICLE_ID              CRASH_DATE  SEAT_NO     CITY STATE ZIPCODE SEX  \\\n",
      "0    834816.0  09/28/2019 03:30:00 AM      NaN  CHICAGO    IL   60651   M   \n",
      "\n",
      "   ...  EMS_RUN_NO DRIVER_ACTION DRIVER_VISION PHYSICAL_CONDITION  \\\n",
      "0  ...         NaN       UNKNOWN       UNKNOWN            UNKNOWN   \n",
      "\n",
      "  PEDPEDAL_ACTION PEDPEDAL_VISIBILITY PEDPEDAL_LOCATION        BAC_RESULT  \\\n",
      "0             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
      "\n",
      "  BAC_RESULT VALUE CELL_PHONE_USE  \n",
      "0              NaN            NaN  \n",
      "\n",
      "[1 rows x 29 columns] \n",
      "\n",
      "traffic_crashes DataFrame:\n",
      "                                     CRASH_RECORD_ID CRASH_DATE_EST_I  \\\n",
      "0  6c1659069e9c6285a650e70d6f9b574ed5f64c12888479...              NaN   \n",
      "\n",
      "               CRASH_DATE  POSTED_SPEED_LIMIT TRAFFIC_CONTROL_DEVICE  \\\n",
      "0  08/18/2023 12:50:00 PM                  15                  OTHER   \n",
      "\n",
      "       DEVICE_CONDITION WEATHER_CONDITION LIGHTING_CONDITION FIRST_CRASH_TYPE  \\\n",
      "0  FUNCTIONING PROPERLY             CLEAR           DAYLIGHT         REAR END   \n",
      "\n",
      "  TRAFFICWAY_TYPE  ...  INJURIES_NON_INCAPACITATING  \\\n",
      "0           OTHER  ...                          1.0   \n",
      "\n",
      "  INJURIES_REPORTED_NOT_EVIDENT INJURIES_NO_INDICATION INJURIES_UNKNOWN  \\\n",
      "0                           0.0                    1.0              0.0   \n",
      "\n",
      "  CRASH_HOUR CRASH_DAY_OF_WEEK CRASH_MONTH LATITUDE LONGITUDE LOCATION  \n",
      "0         12                 6           8      NaN       NaN      NaN  \n",
      "\n",
      "[1 rows x 48 columns] \n",
      "\n",
      "vehicles DataFrame:\n",
      "   CRASH_UNIT_ID                                    CRASH_RECORD_ID  \\\n",
      "0        1717556  7b1763088507f77e0e552c009a6bf89a4d6330c7527706...   \n",
      "\n",
      "               CRASH_DATE  UNIT_NO UNIT_TYPE  NUM_PASSENGERS  VEHICLE_ID  \\\n",
      "0  12/06/2023 03:24:00 PM        1    DRIVER             NaN   1634931.0   \n",
      "\n",
      "  CMRC_VEH_I    MAKE   MODEL  ... TRAILER1_LENGTH  TRAILER2_LENGTH  \\\n",
      "0        NaN  NISSAN  SENTRA  ...             NaN              NaN   \n",
      "\n",
      "  TOTAL_VEHICLE_LENGTH AXLE_CNT VEHICLE_CONFIG CARGO_BODY_TYPE LOAD_TYPE  \\\n",
      "0                  NaN      NaN            NaN             NaN       NaN   \n",
      "\n",
      "  HAZMAT_OUT_OF_SERVICE_I MCS_OUT_OF_SERVICE_I  HAZMAT_CLASS  \n",
      "0                     NaN                  NaN           NaN  \n",
      "\n",
      "[1 rows x 71 columns] \n",
      "\n",
      "crashes_finalized DataFrame:\n",
      "       lighting_condition roadway_surface_cond speed_limit_category  \\\n",
      "0  darkness, lighted road                  dry               Medium   \n",
      "\n",
      "  traffic_control_category road_category  severity_category  \\\n",
      "0                     Sign       unknown                  0   \n",
      "\n",
      "          crash_cause_category    time_of_day day_of_week  season   sex  \\\n",
      "0  Aggressive/Reckless Driving  Night (Early)         Mon  Winter  male   \n",
      "\n",
      "  age_group airbag_deployed    vehicle_category  maneuver_category  \n",
      "0     27-65    Not Deployed  Passenger Vehicles  Standard Movement   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Verify by displaying the first rows of each dataframe\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name} DataFrame:\")\n",
    "    print(df.head(1), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29905ba",
   "metadata": {},
   "source": [
    "## 2.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355701b1",
   "metadata": {},
   "source": [
    "### 2.1 Crashes\n",
    "\n",
    "The crashes dataset included my target variable, so I was careful with how I handled data cleaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88519c74",
   "metadata": {},
   "source": [
    "My steps included:\n",
    "* **Preview Data**: `.head()`\n",
    "\n",
    "\n",
    "* **Understand Dataset Structure**: `.info()`\n",
    "\n",
    "\n",
    "* **Format Feature Names and Row Values**: `.lower()`\n",
    "\n",
    "\n",
    "* **Drop features with overly high null values**: `.isna().sum()/ len(df)` for percentage of nulls for each feature\n",
    "\n",
    "\n",
    "* **Check for duplicates**: `.duplicated().sum()`\n",
    "\n",
    "\n",
    "* **Keep or drop features with remaining nulls**:\n",
    "\n",
    "    * make intentional decisions to keep or drop using `.value_counts()` distribution and domain knowledge\n",
    "\n",
    "\n",
    "* **inspect remaining features**: `.value_counts()`; \n",
    "\n",
    "    * make intentional decisions to keep or drop using `.value_counts()` distribution and domain knowledge; \n",
    "    * make note of any features to keep that will need cleaning/cardinality reduction/etc.\n",
    "\n",
    "\n",
    "* **remove unuseful features**: \n",
    "\n",
    "    * `.drop()` for list of features deemed not useful for analysis; \n",
    "    * store trimmed df as 'df_name_cleaned'\n",
    "    \n",
    "\n",
    "* **reduce feature cardinality with label reclassification**:\n",
    "\n",
    "    * `trafficway_type` and `lane_cnt`\n",
    "    * `crash_hour`, `crash_day_of_week`, `crash_month`\n",
    "    * `posted_speed_limit`\n",
    "    * `traffic_control_device`\n",
    "    * `prim_contributory_cause`\n",
    "    * `most_severe_injury`\n",
    " \n",
    " \n",
    "* **Convert data types**: \n",
    "\n",
    "    * stored data types to reflect true data types \n",
    "    * (text variables as strings, numeric variables as int, categorical as category, ect.)\n",
    "    \n",
    " \n",
    "* **remove remaining nulls**: `.dropna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f2db7",
   "metadata": {},
   "source": [
    "#### 2.1.1 Preview Data: `.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0572454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH_RECORD_ID</th>\n",
       "      <th>CRASH_DATE_EST_I</th>\n",
       "      <th>CRASH_DATE</th>\n",
       "      <th>POSTED_SPEED_LIMIT</th>\n",
       "      <th>TRAFFIC_CONTROL_DEVICE</th>\n",
       "      <th>DEVICE_CONDITION</th>\n",
       "      <th>WEATHER_CONDITION</th>\n",
       "      <th>LIGHTING_CONDITION</th>\n",
       "      <th>FIRST_CRASH_TYPE</th>\n",
       "      <th>TRAFFICWAY_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>INJURIES_NON_INCAPACITATING</th>\n",
       "      <th>INJURIES_REPORTED_NOT_EVIDENT</th>\n",
       "      <th>INJURIES_NO_INDICATION</th>\n",
       "      <th>INJURIES_UNKNOWN</th>\n",
       "      <th>CRASH_HOUR</th>\n",
       "      <th>CRASH_DAY_OF_WEEK</th>\n",
       "      <th>CRASH_MONTH</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6c1659069e9c6285a650e70d6f9b574ed5f64c12888479...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/18/2023 12:50:00 PM</td>\n",
       "      <td>15</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>FUNCTIONING PROPERLY</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>REAR END</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5f54a59fcb087b12ae5b1acff96a3caf4f2d37e79f8db4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/29/2023 02:45:00 PM</td>\n",
       "      <td>30</td>\n",
       "      <td>TRAFFIC SIGNAL</td>\n",
       "      <td>FUNCTIONING PROPERLY</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>PARKED MOTOR VEHICLE</td>\n",
       "      <td>DIVIDED - W/MEDIAN (NOT RAISED)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>41.854120</td>\n",
       "      <td>-87.665902</td>\n",
       "      <td>POINT (-87.665902342962 41.854120262952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61fcb8c1eb522a6469b460e2134df3d15f82e81fd93e9c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/18/2023 05:58:00 PM</td>\n",
       "      <td>30</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>PEDALCYCLIST</td>\n",
       "      <td>NOT DIVIDED</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>41.942976</td>\n",
       "      <td>-87.761883</td>\n",
       "      <td>POINT (-87.761883496974 41.942975745006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004cd14d0303a9163aad69a2d7f341b7da2a8572b2ab33...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/26/2019 08:38:00 AM</td>\n",
       "      <td>25</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>PEDESTRIAN</td>\n",
       "      <td>ONE-WAY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1d5f0ea90897745365a4cbb06cc60329a120d89753fac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/18/2023 10:45:00 AM</td>\n",
       "      <td>20</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>NO CONTROLS</td>\n",
       "      <td>CLEAR</td>\n",
       "      <td>DAYLIGHT</td>\n",
       "      <td>FIXED OBJECT</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     CRASH_RECORD_ID CRASH_DATE_EST_I  \\\n",
       "0  6c1659069e9c6285a650e70d6f9b574ed5f64c12888479...              NaN   \n",
       "1  5f54a59fcb087b12ae5b1acff96a3caf4f2d37e79f8db4...              NaN   \n",
       "2  61fcb8c1eb522a6469b460e2134df3d15f82e81fd93e9c...              NaN   \n",
       "3  004cd14d0303a9163aad69a2d7f341b7da2a8572b2ab33...              NaN   \n",
       "4  a1d5f0ea90897745365a4cbb06cc60329a120d89753fac...              NaN   \n",
       "\n",
       "               CRASH_DATE  POSTED_SPEED_LIMIT TRAFFIC_CONTROL_DEVICE  \\\n",
       "0  08/18/2023 12:50:00 PM                  15                  OTHER   \n",
       "1  07/29/2023 02:45:00 PM                  30         TRAFFIC SIGNAL   \n",
       "2  08/18/2023 05:58:00 PM                  30            NO CONTROLS   \n",
       "3  11/26/2019 08:38:00 AM                  25            NO CONTROLS   \n",
       "4  08/18/2023 10:45:00 AM                  20            NO CONTROLS   \n",
       "\n",
       "       DEVICE_CONDITION WEATHER_CONDITION LIGHTING_CONDITION  \\\n",
       "0  FUNCTIONING PROPERLY             CLEAR           DAYLIGHT   \n",
       "1  FUNCTIONING PROPERLY             CLEAR           DAYLIGHT   \n",
       "2           NO CONTROLS             CLEAR           DAYLIGHT   \n",
       "3           NO CONTROLS             CLEAR           DAYLIGHT   \n",
       "4           NO CONTROLS             CLEAR           DAYLIGHT   \n",
       "\n",
       "       FIRST_CRASH_TYPE                  TRAFFICWAY_TYPE  ...  \\\n",
       "0              REAR END                            OTHER  ...   \n",
       "1  PARKED MOTOR VEHICLE  DIVIDED - W/MEDIAN (NOT RAISED)  ...   \n",
       "2          PEDALCYCLIST                      NOT DIVIDED  ...   \n",
       "3            PEDESTRIAN                          ONE-WAY  ...   \n",
       "4          FIXED OBJECT                            OTHER  ...   \n",
       "\n",
       "   INJURIES_NON_INCAPACITATING INJURIES_REPORTED_NOT_EVIDENT  \\\n",
       "0                          1.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          1.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "  INJURIES_NO_INDICATION INJURIES_UNKNOWN CRASH_HOUR CRASH_DAY_OF_WEEK  \\\n",
       "0                    1.0              0.0         12                 6   \n",
       "1                    1.0              0.0         14                 7   \n",
       "2                    1.0              0.0         17                 6   \n",
       "3                    1.0              0.0          8                 3   \n",
       "4                    1.0              0.0         10                 6   \n",
       "\n",
       "  CRASH_MONTH   LATITUDE  LONGITUDE                                  LOCATION  \n",
       "0           8        NaN        NaN                                       NaN  \n",
       "1           7  41.854120 -87.665902  POINT (-87.665902342962 41.854120262952)  \n",
       "2           8  41.942976 -87.761883  POINT (-87.761883496974 41.942975745006)  \n",
       "3          11        NaN        NaN                                       NaN  \n",
       "4           8        NaN        NaN                                       NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previews the first 5 rows of the dataframe\n",
    "traffic_crashes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94714fa",
   "metadata": {},
   "source": [
    "#### 2.1.2 Understand Structure: `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e843da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 901446 entries, 0 to 901445\n",
      "Data columns (total 48 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   CRASH_RECORD_ID                901446 non-null  object \n",
      " 1   CRASH_DATE_EST_I               66531 non-null   object \n",
      " 2   CRASH_DATE                     901446 non-null  object \n",
      " 3   POSTED_SPEED_LIMIT             901446 non-null  int64  \n",
      " 4   TRAFFIC_CONTROL_DEVICE         901446 non-null  object \n",
      " 5   DEVICE_CONDITION               901446 non-null  object \n",
      " 6   WEATHER_CONDITION              901446 non-null  object \n",
      " 7   LIGHTING_CONDITION             901446 non-null  object \n",
      " 8   FIRST_CRASH_TYPE               901446 non-null  object \n",
      " 9   TRAFFICWAY_TYPE                901446 non-null  object \n",
      " 10  LANE_CNT                       199022 non-null  float64\n",
      " 11  ALIGNMENT                      901446 non-null  object \n",
      " 12  ROADWAY_SURFACE_COND           901446 non-null  object \n",
      " 13  ROAD_DEFECT                    901446 non-null  object \n",
      " 14  REPORT_TYPE                    873380 non-null  object \n",
      " 15  CRASH_TYPE                     901446 non-null  object \n",
      " 16  INTERSECTION_RELATED_I         207054 non-null  object \n",
      " 17  NOT_RIGHT_OF_WAY_I             41046 non-null   object \n",
      " 18  HIT_AND_RUN_I                  282692 non-null  object \n",
      " 19  DAMAGE                         901446 non-null  object \n",
      " 20  DATE_POLICE_NOTIFIED           901446 non-null  object \n",
      " 21  PRIM_CONTRIBUTORY_CAUSE        901446 non-null  object \n",
      " 22  SEC_CONTRIBUTORY_CAUSE         901446 non-null  object \n",
      " 23  STREET_NO                      901446 non-null  int64  \n",
      " 24  STREET_DIRECTION               901442 non-null  object \n",
      " 25  STREET_NAME                    901445 non-null  object \n",
      " 26  BEAT_OF_OCCURRENCE             901441 non-null  float64\n",
      " 27  PHOTOS_TAKEN_I                 12323 non-null   object \n",
      " 28  STATEMENTS_TAKEN_I             20743 non-null   object \n",
      " 29  DOORING_I                      2856 non-null    object \n",
      " 30  WORK_ZONE_I                    5035 non-null    object \n",
      " 31  WORK_ZONE_TYPE                 3886 non-null    object \n",
      " 32  WORKERS_PRESENT_I              1297 non-null    object \n",
      " 33  NUM_UNITS                      901446 non-null  int64  \n",
      " 34  MOST_SEVERE_INJURY             899453 non-null  object \n",
      " 35  INJURIES_TOTAL                 899467 non-null  float64\n",
      " 36  INJURIES_FATAL                 899467 non-null  float64\n",
      " 37  INJURIES_INCAPACITATING        899467 non-null  float64\n",
      " 38  INJURIES_NON_INCAPACITATING    899467 non-null  float64\n",
      " 39  INJURIES_REPORTED_NOT_EVIDENT  899467 non-null  float64\n",
      " 40  INJURIES_NO_INDICATION         899467 non-null  float64\n",
      " 41  INJURIES_UNKNOWN               899467 non-null  float64\n",
      " 42  CRASH_HOUR                     901446 non-null  int64  \n",
      " 43  CRASH_DAY_OF_WEEK              901446 non-null  int64  \n",
      " 44  CRASH_MONTH                    901446 non-null  int64  \n",
      " 45  LATITUDE                       894920 non-null  float64\n",
      " 46  LONGITUDE                      894920 non-null  float64\n",
      " 47  LOCATION                       894920 non-null  object \n",
      "dtypes: float64(11), int64(6), object(31)\n",
      "memory usage: 330.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# provides info about the dataframe features, non-null values, and datatypes\n",
    "traffic_crashes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e1d60",
   "metadata": {},
   "source": [
    "#### 2.1.3 Format Feature names and Row Values: `.lower()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a6da36",
   "metadata": {},
   "source": [
    "From the first two steps of previewing the data and understanding its structure, two things stand out: There is A LOT of data, and it is messy with varying amounts of null values in each feature. I decided to make the feature names lower case simply for readability, and as a precuror cleaning step I made all string values lower case in the hopes that this may deal with some label misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d28ae58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts all feature names to lower case \n",
    "traffic_crashes_df.columns = traffic_crashes_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecc1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string values in object columns to lowercase\n",
    "for col in traffic_crashes_df.select_dtypes(include='object').columns:\n",
    "    traffic_crashes_df[col] = traffic_crashes_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0367bec",
   "metadata": {},
   "source": [
    "#### 2.1.4 Drop features with overly high null values: \n",
    "\n",
    "While there are a lot of records in this dataframe, some features also have a lot of null values.  I know that features with a significant majority of null values will not be helpful for analysis so I start by trying to identify these features and remove them right off the bat. Rather than look at the count of nulls, I used `(.isna().sum()/ len(df)) *100` to get the percentage of nulls for each feature. This is easier to grasp than null counts in the 10 and hundred thousands. \n",
    "\n",
    "For quick cleaning, I chose a 90% null threshold to automatically remove features. For the features with between 60-90% nulls, I decided to inspect them more closely before blinding removing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae7df88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id                   0.00\n",
       "crash_date_est_i                 92.62\n",
       "crash_date                        0.00\n",
       "posted_speed_limit                0.00\n",
       "traffic_control_device            0.00\n",
       "device_condition                  0.00\n",
       "weather_condition                 0.00\n",
       "lighting_condition                0.00\n",
       "first_crash_type                  0.00\n",
       "trafficway_type                   0.00\n",
       "lane_cnt                         77.92\n",
       "alignment                         0.00\n",
       "roadway_surface_cond              0.00\n",
       "road_defect                       0.00\n",
       "report_type                       3.11\n",
       "crash_type                        0.00\n",
       "intersection_related_i           77.03\n",
       "not_right_of_way_i               95.45\n",
       "hit_and_run_i                    68.64\n",
       "damage                            0.00\n",
       "date_police_notified              0.00\n",
       "prim_contributory_cause           0.00\n",
       "sec_contributory_cause            0.00\n",
       "street_no                         0.00\n",
       "street_direction                  0.00\n",
       "street_name                       0.00\n",
       "beat_of_occurrence                0.00\n",
       "photos_taken_i                   98.63\n",
       "statements_taken_i               97.70\n",
       "dooring_i                        99.68\n",
       "work_zone_i                      99.44\n",
       "work_zone_type                   99.57\n",
       "workers_present_i                99.86\n",
       "num_units                         0.00\n",
       "most_severe_injury                0.22\n",
       "injuries_total                    0.22\n",
       "injuries_fatal                    0.22\n",
       "injuries_incapacitating           0.22\n",
       "injuries_non_incapacitating       0.22\n",
       "injuries_reported_not_evident     0.22\n",
       "injuries_no_indication            0.22\n",
       "injuries_unknown                  0.22\n",
       "crash_hour                        0.00\n",
       "crash_day_of_week                 0.00\n",
       "crash_month                       0.00\n",
       "latitude                          0.72\n",
       "longitude                         0.72\n",
       "location                          0.72\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stores the percentages of null values for each feature, rounded to 2 places, in a variable\n",
    "missing_percentage = round((traffic_crashes_df.isna().sum()/len(traffic_crashes_df)*100), 2)\n",
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ecd73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting all features with 90% or more of its values are null\n",
    "high_null_features = traffic_crashes_df.columns[(traffic_crashes_df.isna().sum() / len(traffic_crashes_df) * 100) >= 90]\n",
    "high_null_features\n",
    "\n",
    "# creating a list of features with 90% or more null values\n",
    "high_null_features_list = list(high_null_features)\n",
    "high_null_features_list\n",
    "\n",
    "crashes_cleaned = traffic_crashes_df.drop(columns=high_null_features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad206653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crash_date_est_i', 'not_right_of_way_i', 'photos_taken_i',\n",
       "       'statements_taken_i', 'dooring_i', 'work_zone_i', 'work_zone_type',\n",
       "       'workers_present_i'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting all features with 90% or more of its values are null\n",
    "high_null_features = traffic_crashes_df.columns[(traffic_crashes_df.isna().sum() / len(traffic_crashes_df) * 100) >= 90]\n",
    "high_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e2ff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crash_date_est_i',\n",
       " 'not_right_of_way_i',\n",
       " 'photos_taken_i',\n",
       " 'statements_taken_i',\n",
       " 'dooring_i',\n",
       " 'work_zone_i',\n",
       " 'work_zone_type',\n",
       " 'workers_present_i']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of features with 90% or more null values\n",
    "high_null_features_list = list(high_null_features)\n",
    "high_null_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2d3e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops all features with 90% or more null values, saves the new datafram as crashes_cleaned\n",
    "crashes_cleaned = traffic_crashes_df.drop(columns=high_null_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbc140",
   "metadata": {},
   "source": [
    "#### 2.1.5 Check for duplicates: `.duplicated().sum()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a0b13",
   "metadata": {},
   "source": [
    "Checking for duplicate rows is another common cleaning step. In this case, there were no duplicate rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b8e5647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate crash_record_id values in crashes_cleaned: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate crash_record_id values in crashes_cleaned\n",
    "print(f\"Number of duplicate crash_record_id values in crashes_cleaned: {crashes_cleaned['crash_record_id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9514663",
   "metadata": {},
   "source": [
    "#### 2.1.6 Keep or drop features with remaining nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de73e6e",
   "metadata": {},
   "source": [
    "As mentioned earlier, I wanted at least look at features with between 60-90% null values before removing them so I inspected the value_counts() for these 3 features:\n",
    "* `hit_and_run_i` describes the aftermath of the crash, not a contributing factor so I drop this\n",
    "* `intersection_related_i` initially seems like it could be a good feature to keep, but upon further inspection, it appears to be vague. CDOT's definition: \"A field observation by the police officer whether an intersection played a role in the crash. Does not represent whether or not the crash occurred within the intersection\", makes me feel confident removing this as it seems like it is ultimally up to the officer's disgretion, which may not lead to useful analysis, so I dropped it. \n",
    "* `lane_cnt`: Despite the high percentage of null values I decided to keep this. My domain knowledge makes me think the number of lanes could affect how cautiously or uncautiously drivers driver. Drivers generally will drive more cautiously down a narrow two or one lane, than on an open 6 lane freeway. \n",
    "\n",
    "Once I created a new dataframe, leaving out features I removed, no longer needed the original dataset so I deleted it from memory due to its large size and ability to take up a large amount of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b6f5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves all features with between 60%-90% null values as a variable\n",
    "\n",
    "medium_null_features = traffic_crashes_df.columns[\n",
    "    ((traffic_crashes_df.isna().sum() / len(traffic_crashes_df) * 100) >= 60) &\n",
    "    ((traffic_crashes_df.isna().sum() / len(traffic_crashes_df) * 100) < 90)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a6f3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the above variable to list type\n",
    "medium_null_features_list = list(medium_null_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ddbc1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for column 'lane_cnt':\n",
      "2.0          91162\n",
      "4.0          49589\n",
      "1.0          32550\n",
      "3.0           8678\n",
      "0.0           8032\n",
      "6.0           4502\n",
      "5.0           1940\n",
      "8.0           1908\n",
      "7.0            184\n",
      "10.0           162\n",
      "99.0           108\n",
      "9.0             66\n",
      "11.0            30\n",
      "12.0            29\n",
      "20.0            15\n",
      "22.0            13\n",
      "15.0             7\n",
      "16.0             7\n",
      "14.0             5\n",
      "30.0             5\n",
      "40.0             4\n",
      "60.0             3\n",
      "21.0             3\n",
      "25.0             2\n",
      "100.0            2\n",
      "902.0            1\n",
      "24.0             1\n",
      "80.0             1\n",
      "218474.0         1\n",
      "45.0             1\n",
      "17.0             1\n",
      "299679.0         1\n",
      "19.0             1\n",
      "400.0            1\n",
      "13.0             1\n",
      "1191625.0        1\n",
      "35.0             1\n",
      "433634.0         1\n",
      "41.0             1\n",
      "28.0             1\n",
      "44.0             1\n",
      "Name: lane_cnt, dtype: int64\n",
      "--------------------------------\n",
      "Value counts for column 'intersection_related_i':\n",
      "y    197181\n",
      "n      9873\n",
      "Name: intersection_related_i, dtype: int64\n",
      "--------------------------------\n",
      "Value counts for column 'hit_and_run_i':\n",
      "y    270587\n",
      "n     12105\n",
      "Name: hit_and_run_i, dtype: int64\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# iterates through list of medium null features and prints the value_counts() for each\n",
    "for feature in medium_null_features_list:\n",
    "    print(f\"Value counts for column '{feature}':\")\n",
    "    print(crashes_cleaned[feature].value_counts())\n",
    "    print(\"-\"* 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf53516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes the traffic_crashes_df dataframe to clear up memory\n",
    "\n",
    "del traffic_crashes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49131d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95b213",
   "metadata": {},
   "source": [
    "#### 2.1.7 Inspect remaining features: `.value_counts()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f288853",
   "metadata": {},
   "source": [
    "Once columns with null values were taken care of, I used `.value_counts()` to inspect many of the remaining columns to look for things like cardianlity, misspelling, class labels, stored data types, etc. I used some domain knowledge to avoid looking through every single feature. \n",
    "\n",
    "Some features that I decided to keep because they might be helpful in predicting my target had unclear labels or a high number of labels (aka high cardinality). In order to make sure these features were not only useful for analysis, but also ready for the modeling phase, I used some domain knowledge to help reclassify some of the feature labels into less, more easily understandable labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15a99878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.976201    1438\n",
       "41.900959     817\n",
       "41.791420     628\n",
       "41.751461     615\n",
       "41.722257     489\n",
       "             ... \n",
       "41.812116       1\n",
       "41.742553       1\n",
       "41.757199       1\n",
       "41.936622       1\n",
       "41.951640       1\n",
       "Name: latitude, Length: 319343, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within latitude feature\n",
    "crashes_cleaned['latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33548168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.905309    1438\n",
       "-87.619928     817\n",
       "-87.580148     628\n",
       "-87.585972     615\n",
       "-87.585276     489\n",
       "              ... \n",
       "-87.610788       1\n",
       "-87.555370       1\n",
       "-87.647808       1\n",
       "-87.616396       1\n",
       "-87.732269       1\n",
       "Name: longitude, Length: 319308, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within longitude feature\n",
    "crashes_cleaned['longitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b38608d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "point (-87.905309125103 41.976201139024)    1438\n",
       "point (-87.619928173678 41.900958919109)     817\n",
       "point (-87.580147768689 41.791420282098)     628\n",
       "point (-87.585971992965 41.751460603167)     615\n",
       "point (-87.585275565077 41.722257273006)     489\n",
       "                                            ... \n",
       "point (-87.639121523275 41.869503004763)       1\n",
       "point (-87.602411667064 41.804009965883)       1\n",
       "point (-87.674723215169 41.96342865936)        1\n",
       "point (-87.755347401896 41.896861551221)       1\n",
       "point (-87.732268503259 41.951640180538)       1\n",
       "Name: location, Length: 319546, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within location feature\n",
    "crashes_cleaned['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919396f",
   "metadata": {},
   "source": [
    "While location data seems like it be very insightful, the cardinality is simply too high to help with predictive capacity, and will ultimately restrict my limited computing power. With more time, in future iterations of this project I hope to be able to process the location data to be insightful and able to be kept, but for the purposes of a minimum viable product, I'll remove lat, long, and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b68d2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    664045\n",
       "35     59626\n",
       "25     57789\n",
       "20     37717\n",
       "15     32112\n",
       "10     21096\n",
       "40      8612\n",
       "0       7584\n",
       "45      5951\n",
       "5       4957\n",
       "55       883\n",
       "50       276\n",
       "3        221\n",
       "9         96\n",
       "39        95\n",
       "99        66\n",
       "60        53\n",
       "1         41\n",
       "24        38\n",
       "2         31\n",
       "65        20\n",
       "32        20\n",
       "34        16\n",
       "33        14\n",
       "11        11\n",
       "26        11\n",
       "36         8\n",
       "6          7\n",
       "70         7\n",
       "7          6\n",
       "18         4\n",
       "12         4\n",
       "22         4\n",
       "14         4\n",
       "23         3\n",
       "29         3\n",
       "31         2\n",
       "8          2\n",
       "38         2\n",
       "16         2\n",
       "4          2\n",
       "62         1\n",
       "63         1\n",
       "44         1\n",
       "49         1\n",
       "46         1\n",
       "Name: posted_speed_limit, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within posted_speed_limit feature\n",
    "crashes_cleaned['posted_speed_limit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb2fa3",
   "metadata": {},
   "source": [
    "This feature could be important, but will require cardinality reduction. To help make this feature better able to be handled for modeling I decided to reclassify this feature into 3 speed groups: low (**0-25** mph), medium (**26-40** mph), and high (**40+ mph**). \n",
    "\n",
    "These decisions were intentional as both reports from Philadelphia's and Chicago's transportation department site speed as a key factor with speeds greater than 40 resulting in high probability of death for pedestrians if hit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3e900d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    732454\n",
       "Low       161731\n",
       "High        7261\n",
       "Name: speed_limit_category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorize speed limits directly without using a function\n",
    "crashes_cleaned['speed_limit_category'] = pd.cut(\n",
    "    crashes_cleaned['posted_speed_limit'],\n",
    "    bins=[-float('inf'), 25, 40, float('inf')],\n",
    "    labels=['Low', 'Medium', 'High'],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# Check the result\n",
    "crashes_cleaned['speed_limit_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fb837ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no controls                 510287\n",
       "traffic signal              249882\n",
       "stop sign/flasher            89361\n",
       "unknown                      38328\n",
       "other                         6096\n",
       "yield                         1365\n",
       "lane use marking              1226\n",
       "other reg. sign               1103\n",
       "other warning sign             715\n",
       "pedestrian crossing sign       636\n",
       "railroad crossing gate         581\n",
       "flashing control signal        373\n",
       "school zone                    353\n",
       "delineators                    352\n",
       "police/flagman                 309\n",
       "rr crossing sign               195\n",
       "other railroad crossing        192\n",
       "no passing                      58\n",
       "bicycle crossing sign           34\n",
       "Name: traffic_control_device, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within traffic_control_device feature\n",
    "crashes_cleaned['traffic_control_device'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4bc90",
   "metadata": {},
   "source": [
    "During my time working with Philadelphia's Vision Zero department, I learned that traffic light signals have the potential to increase chances of speeding as opposed to stop signs, mainly in the context of drivers speeding up at yellow lights to not get stuck at the light. With this knowledge, I feel like this feature could be an insightful predictor, but will need to reduce its cardinality. I reclassified this feature into 4 categories: Signal, sign, markings & lanes, and other. Reduced cardinality will reduce the dimensionality during OneHotEncoding, leading to improved computational efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8d231f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other               555212\n",
       "Signal              251472\n",
       "Sign                 91886\n",
       "Markings & Lanes      1578\n",
       "Name: traffic_control_category, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map the original 'traffic_control_device' values to more specific categories\n",
    "traffic_control_mapping = {\n",
    "    'traffic signal': 'Signal',\n",
    "    'flashing control signal': 'Signal',\n",
    "    'pedestrian crossing sign': 'Signal',  # If it's a signal\n",
    "    'railroad crossing gate': 'Signal',    # If it uses lights\n",
    "    \n",
    "    'stop sign/flasher': 'Sign',\n",
    "    'yield': 'Sign',\n",
    "    'school zone': 'Sign',\n",
    "    'railroad crossing sign': 'Sign',      # If static sign\n",
    "    'other warning sign': 'Sign',\n",
    "    'bicycle crossing sign': 'Sign',\n",
    "    'no passing': 'Sign',\n",
    "    \n",
    "    'lane use marking': 'Markings & Lanes',\n",
    "    'delineators': 'Markings & Lanes',\n",
    "    \n",
    "    'no controls': 'Other',\n",
    "    'unknown': 'Other',\n",
    "    'other': 'Other',\n",
    "    'police/flagman': 'Other',\n",
    "    'other railroad crossing': 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'traffic_control_device' column\n",
    "crashes_cleaned['traffic_control_category'] = crashes_cleaned['traffic_control_device'].map(traffic_control_mapping)\n",
    "\n",
    "# Check the value counts for the new grouped categories\n",
    "crashes_cleaned['traffic_control_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e228eaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no controls                 516329\n",
       "functioning properly        307784\n",
       "unknown                      63428\n",
       "other                         6836\n",
       "functioning improperly        4113\n",
       "not functioning               2562\n",
       "worn reflective material       295\n",
       "missing                         99\n",
       "Name: device_condition, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within device_condition feature\n",
    "crashes_cleaned['device_condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b5f6f",
   "metadata": {},
   "source": [
    "The top two categories that make up the majority of this feature are 'no controls' and 'functioning properly'. Then the next two frequent classes are 'unknown' and 'other'. Due to this, this feature does not feel like it will be particularly insightful, so we can drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eefee8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "daylight                  578548\n",
       "darkness, lighted road    197098\n",
       "unknown                    42569\n",
       "darkness                   42455\n",
       "dusk                       25737\n",
       "dawn                       15039\n",
       "Name: lighting_condition, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within lighting_condition feature\n",
    "crashes_cleaned['lighting_condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8adee",
   "metadata": {},
   "source": [
    "This seems like it could offer insightful predictive capacity, and the cardinality is not high. I will keep this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b283881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parked motor vehicle            208646\n",
       "rear end                        199321\n",
       "sideswipe same direction        138501\n",
       "turning                         129668\n",
       "angle                            97996\n",
       "fixed object                     41874\n",
       "pedestrian                       21320\n",
       "pedalcyclist                     14331\n",
       "sideswipe opposite direction     12509\n",
       "rear to front                     9252\n",
       "other object                      8981\n",
       "head on                           7639\n",
       "rear to side                      5512\n",
       "other noncollision                2745\n",
       "rear to rear                      1907\n",
       "animal                             655\n",
       "overturned                         543\n",
       "train                               46\n",
       "Name: first_crash_type, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within first_crash_type feature\n",
    "crashes_cleaned['first_crash_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff23e3c",
   "metadata": {},
   "source": [
    "This information seems like it could be somewhat potentially insightful, but I feel other features will offer better insights. So in an effort to reduce the dataset to only the most useful features, I will remove this feature. This could be a feature to include in future iterations of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f3b1b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not divided                        388246\n",
       "divided - w/median (not raised)    142466\n",
       "one-way                            114072\n",
       "four way                            62561\n",
       "parking lot                         61011\n",
       "divided - w/median barrier          50946\n",
       "other                               24388\n",
       "alley                               14802\n",
       "t-intersection                      12409\n",
       "unknown                             10603\n",
       "center turn lane                     6374\n",
       "driveway                             2890\n",
       "ramp                                 2834\n",
       "unknown intersection type            2762\n",
       "five point, or more                  1385\n",
       "y-intersection                       1350\n",
       "traffic route                        1166\n",
       "not reported                          687\n",
       "roundabout                            308\n",
       "l-intersection                        186\n",
       "Name: trafficway_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within trafficway_type feature\n",
    "crashes_cleaned['trafficway_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574acf76",
   "metadata": {},
   "source": [
    "This information feels like it could be important but I will keep this feature. With some label reclassification I reduce this feature down to 7 categories, making for a more insightful and computationally efficient feature for prediction. The new reclassified feature's name is 'road_category' so I will keep it and drop the original trafficway_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6500cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intersection types\n",
    "intersection_types = ['roundabout', 'l-intersection', 'y-intersection', \n",
    "                      'five point, or more', 'center turn lane', \n",
    "                      't-intersection', 'unknown intersection type']\n",
    "\n",
    "# Define conditions for both blocks (with block 2 modification)\n",
    "conditions = [\n",
    "    (crashes_cleaned['trafficway_type'] == 'one-way') & (crashes_cleaned['lane_cnt'] == 1),\n",
    "    (crashes_cleaned['trafficway_type'] == 'one-way') & (crashes_cleaned['lane_cnt'] > 1),\n",
    "    (crashes_cleaned['trafficway_type'].isin(intersection_types)),\n",
    "    (crashes_cleaned['trafficway_type'].isin(['unknown', 'not reported'])) | \n",
    "    (pd.isnull(crashes_cleaned['trafficway_type'])) | \n",
    "    (pd.isnull(crashes_cleaned['lane_cnt'])),\n",
    "    (crashes_cleaned['trafficway_type'].isin(['parking lot', 'driveway', 'ramp', 'alley', 'other'])),\n",
    "    # Modified condition for 'multi-lane bidirectional' from Block 2\n",
    "    (crashes_cleaned['lane_cnt'] > 1) & \n",
    "    (~crashes_cleaned['trafficway_type'].isin([\n",
    "        'one-way', 'four way', 'unknown', 'not reported', \n",
    "        'other', 'parking lot', 'driveway', 'ramp', 'alley'\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Define corresponding categories\n",
    "choices = [\n",
    "    'single-lane one way',\n",
    "    'multi-lane one way',\n",
    "    'intersection',\n",
    "    'unknown',  # Combined \"unknown\" and \"not reported\"\n",
    "    'other',\n",
    "    'multi-lane bidirectional'\n",
    "]\n",
    "\n",
    "# Apply classification\n",
    "crashes_cleaned['road_category'] = np.select(conditions, choices, default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7098a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                     689310\n",
       "multi-lane bidirectional    138918\n",
       "intersection                 24774\n",
       "other                        19589\n",
       "single-lane one way          17992\n",
       "multi-lane one way           10863\n",
       "Name: road_category, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of categories in the new column\n",
    "crashes_cleaned['road_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37be4195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "straight and level       880103\n",
       "straight on grade         11022\n",
       "curve, level               6352\n",
       "straight on hillcrest      2267\n",
       "curve on grade             1313\n",
       "curve on hillcrest          389\n",
       "Name: alignment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within alignment feature\n",
    "crashes_cleaned['alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c9d11",
   "metadata": {},
   "source": [
    "While this feature would ideally be helpful as a predictor, the data here is not conducive for analysis. Most of the entries are 'straight and level', so I will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36a70b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clear                       709235\n",
       "rain                         77962\n",
       "unknown                      51500\n",
       "snow                         28844\n",
       "cloudy/overcast              26333\n",
       "other                         2789\n",
       "freezing rain/drizzle         1787\n",
       "fog/smoke/haze                1353\n",
       "sleet/hail                    1026\n",
       "blowing snow                   453\n",
       "severe cross wind gate         156\n",
       "blowing sand, soil, dirt         8\n",
       "Name: weather_condition, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within weather_condition feature\n",
    "crashes_cleaned['weather_condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cedc",
   "metadata": {},
   "source": [
    "This feature seems important, but will have to compare it to roadway_surface_cond feature as they both contain similar information. I will make a decision about which will be most insightful, and drop the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a36f2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dry                667224\n",
       "wet                117323\n",
       "unknown             80085\n",
       "snow or slush       28524\n",
       "ice                  5678\n",
       "other                2290\n",
       "sand, mud, dirt       322\n",
       "Name: roadway_surface_cond, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within roadway_surface_cond feature\n",
    "crashes_cleaned['roadway_surface_cond'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f207464",
   "metadata": {},
   "source": [
    "This is somewhat redundant with weather condition. I chose to remove weather_condition  and keep roadway_surface_cond due to its lower cardinality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d96c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w    322771\n",
       "s    301079\n",
       "n    216752\n",
       "e     60840\n",
       "Name: street_direction, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within street_direction feature\n",
    "crashes_cleaned['street_direction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5afda",
   "metadata": {},
   "source": [
    "Even though it feel like there could be some predictive power with this feature, I chose to drop it as I think it will not be as insightful as other features, and with the vast amount of features across 3 datasets, I am only trying to keep the ones I feel are most important. With more time I could potentially run a simple decision tree and obtain the feature_importances to help with this decision, but with an approaching deadline I opt to simply remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ddca8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "western ave        24619\n",
       "pulaski rd         21778\n",
       "cicero ave         20285\n",
       "ashland ave        19606\n",
       "halsted st         17440\n",
       "                   ...  \n",
       "franklin sd            1\n",
       "lacey ave              1\n",
       "stetson sub ave        1\n",
       "11th pl                1\n",
       "29th pl                1\n",
       "Name: street_name, Length: 1648, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within street_name feature\n",
    "crashes_cleaned['street_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c046e41",
   "metadata": {},
   "source": [
    "Again I feel like this could offer some predictive insights, but due to its high cardinality I will remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "987eb3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no defects           718022\n",
       "unknown              166233\n",
       "rut, holes             6350\n",
       "other                  4893\n",
       "worn surface           3741\n",
       "shoulder defect        1547\n",
       "debris on roadway       660\n",
       "Name: road_defect, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within road_defect feature\n",
    "crashes_cleaned['road_defect'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58141a3",
   "metadata": {},
   "source": [
    "The main two labels here are \"no defects\" and unknown. This will not be helpful for analysis, so I will remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "079d7910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no injury / drive away              658842\n",
       "injury and / or tow due to crash    242604\n",
       "Name: crash_type, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "crashes_cleaned['crash_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a3c0d",
   "metadata": {},
   "source": [
    "This feature describes the aftermath of the crash which is not helpful for this model. I will remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a277955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834.0    10913\n",
       "114.0      9281\n",
       "813.0      9093\n",
       "815.0      8590\n",
       "1831.0     8244\n",
       "          ...  \n",
       "1653.0      502\n",
       "1655.0      313\n",
       "1652.0      241\n",
       "1650.0       69\n",
       "6100.0        7\n",
       "Name: beat_of_occurrence, Length: 276, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within beat_of_occurrence feature\n",
    "crashes_cleaned['beat_of_occurrence'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916eba",
   "metadata": {},
   "source": [
    "Another potentially insightful feature but with high cardinality, and limited computing power, I choose to remove this. In future iterations, it would be interesting to inspect this feature further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dda8640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no indication of injury     772801\n",
       "nonincapacitating injury     71130\n",
       "reported, not evident        39463\n",
       "incapacitating injury        15074\n",
       "fatal                          985\n",
       "Name: most_severe_injury, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within most_severe_injury feature\n",
    "crashes_cleaned['most_severe_injury'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097801c3",
   "metadata": {},
   "source": [
    "This is my target variable, so I will keep it, but to improve its interpretability and ensure it is aligned with the problem context of predicting fatal or serious injuries, I reclassify it to have two classes: non-serious injury and serious injury. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a32b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the string 'nan' with actual NaN values\n",
    "crashes_cleaned['most_severe_injury'] = crashes_cleaned['most_severe_injury'].replace('nan', np.nan)\n",
    "\n",
    "# Now categorize the injuries into 'Serious' and 'Non-serious'\n",
    "crashes_cleaned['severity_category'] = crashes_cleaned['most_severe_injury'].replace({\n",
    "    'no indication of injury': 'Non-serious',\n",
    "    'nonincapacitating injury': 'Non-serious',\n",
    "    'reported, not evident': 'Non-serious',\n",
    "    'incapacitating injury': 'Serious',\n",
    "    'fatal': 'Serious'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4930b12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     772815\n",
       "1.0      95189\n",
       "2.0      21269\n",
       "3.0       6479\n",
       "4.0       2302\n",
       "5.0        825\n",
       "6.0        325\n",
       "7.0        133\n",
       "8.0         53\n",
       "9.0         27\n",
       "10.0        16\n",
       "11.0         9\n",
       "15.0         8\n",
       "12.0         6\n",
       "21.0         4\n",
       "13.0         3\n",
       "17.0         1\n",
       "14.0         1\n",
       "19.0         1\n",
       "16.0         1\n",
       "Name: injuries_total, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within injuries_total feature\n",
    "crashes_cleaned['injuries_total'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43750be5",
   "metadata": {},
   "source": [
    "This information is redundant with my target so I choose to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9005a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    898482\n",
       "1.0       912\n",
       "2.0        64\n",
       "3.0         8\n",
       "4.0         1\n",
       "Name: injuries_fatal, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within injuries_fatal feature\n",
    "crashes_cleaned['injuries_fatal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac0859",
   "metadata": {},
   "source": [
    "This information is redundant with my target so I choose to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "deba280d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     884243\n",
       "1.0      13370\n",
       "2.0       1395\n",
       "3.0        312\n",
       "4.0        107\n",
       "5.0         29\n",
       "6.0          7\n",
       "7.0          2\n",
       "10.0         1\n",
       "8.0          1\n",
       "Name: injuries_incapacitating, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within injuries_incapacitating feature\n",
    "crashes_cleaned['injuries_incapacitating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c4369",
   "metadata": {},
   "source": [
    "This information is redundant with my target so I choose to drop it. This information is captured in the 'most_severe_injury' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7895ffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unable to determine                                                                 352689\n",
       "failing to yield right-of-way                                                        99589\n",
       "following too closely                                                                86950\n",
       "not applicable                                                                       47632\n",
       "improper overtaking/passing                                                          44963\n",
       "failing to reduce speed to avoid crash                                               37868\n",
       "improper backing                                                                     34796\n",
       "improper lane usage                                                                  32108\n",
       "driving skills/knowledge/experience                                                  30632\n",
       "improper turning/no signal                                                           30203\n",
       "disregarding traffic signals                                                         17608\n",
       "weather                                                                              12961\n",
       "operating vehicle in erratic, reckless, careless, negligent or aggressive manner     11347\n",
       "disregarding stop sign                                                                9609\n",
       "distraction - from inside vehicle                                                     6092\n",
       "equipment - vehicle condition                                                         5576\n",
       "physical condition of driver                                                          5305\n",
       "vision obscured (signs, tree limbs, buildings, etc.)                                  5116\n",
       "driving on wrong side/wrong way                                                       4885\n",
       "under the influence of alcohol/drugs (use when arrest is effected)                    4183\n",
       "distraction - from outside vehicle                                                    3613\n",
       "road engineering/surface/marking defects                                              2129\n",
       "exceeding authorized speed limit                                                      1982\n",
       "disregarding other traffic signs                                                      1914\n",
       "road construction/maintenance                                                         1884\n",
       "exceeding safe speed for conditions                                                   1684\n",
       "evasive action due to animal, object, nonmotorist                                     1627\n",
       "cell phone use other than texting                                                     1188\n",
       "disregarding road markings                                                            1106\n",
       "had been drinking (use when arrest is not made)                                        905\n",
       "animal                                                                                 766\n",
       "turning right on red                                                                   687\n",
       "related to bus stop                                                                    481\n",
       "distraction - other electronic device (navigation device, dvd player, etc.)            425\n",
       "texting                                                                                343\n",
       "disregarding yield sign                                                                279\n",
       "passing stopped school bus                                                             110\n",
       "obstructed crosswalks                                                                  100\n",
       "bicycle advancing legally on red light                                                  88\n",
       "motorcycle advancing legally on red light                                               23\n",
       "Name: prim_contributory_cause, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within prim_contributory_cause feature\n",
    "crashes_cleaned['prim_contributory_cause'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd66bd8f",
   "metadata": {},
   "source": [
    "This feature feels like it is particularly insightful so I will keep it, but will perform label reclassification to better prepare it for modeling by reducing cardinality, and improve interpretability using more understandable grouping labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35eefd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for the primary contributory causes\n",
    "cause_mapping = {\n",
    "    'distraction - from inside vehicle': 'Distraction',\n",
    "    'distraction - from outside vehicle': 'Distraction',\n",
    "    'cell phone use other than texting': 'Distraction',\n",
    "    'distraction - other electronic device (navigation device, dvd player, etc.)': 'Distraction',\n",
    "    'texting': 'Distraction',\n",
    "    'bicycle advancing legally on red light': 'Distraction',\n",
    "    'motorcycle advancing legally on red light': 'Distraction',\n",
    "    \n",
    "    'operating vehicle in erratic, reckless, careless, negligent or aggressive manner': 'Aggressive/Reckless Driving',\n",
    "    'failing to reduce speed to avoid crash': 'Aggressive/Reckless Driving',\n",
    "    'exceeding authorized speed limit': 'Aggressive/Reckless Driving',\n",
    "    'exceeding safe speed for conditions': 'Aggressive/Reckless Driving',\n",
    "    'driving on wrong side/wrong way': 'Aggressive/Reckless Driving',\n",
    "    'disregarding stop sign': 'Aggressive/Reckless Driving',\n",
    "    'disregarding traffic signals': 'Aggressive/Reckless Driving',\n",
    "    'disregarding yield sign': 'Aggressive/Reckless Driving',\n",
    "    'passing stopped school bus': 'Aggressive/Reckless Driving',\n",
    "    'improper overtaking/passing': 'Aggressive/Reckless Driving',\n",
    "    'failing to yield right-of-way': 'Aggressive/Reckless Driving',\n",
    "    'following too closely': 'Aggressive/Reckless Driving',\n",
    "    'improper lane usage': 'Aggressive/Reckless Driving',\n",
    "    'improper turning/no signal': 'Aggressive/Reckless Driving',\n",
    "    \n",
    "    'driving skills/knowledge/experience': 'Driver\\'s Condition/Experience',\n",
    "    'physical condition of driver': 'Driver\\'s Condition/Experience',\n",
    "    'vision obscured (signs, tree limbs, buildings, etc.)': 'Driver\\'s Condition/Experience',\n",
    "    'under the influence of alcohol/drugs (use when arrest is effected)': 'Driver\\'s Condition/Experience',\n",
    "    'had been drinking (use when arrest is not made)': 'Driver\\'s Condition/Experience',\n",
    "    \n",
    "    'weather': 'Environmental and Road Conditions',\n",
    "    'road engineering/surface/marking defects': 'Environmental and Road Conditions',\n",
    "    'road construction/maintenance': 'Environmental and Road Conditions',\n",
    "    'evasive action due to animal, object, nonmotorist': 'Environmental and Road Conditions',\n",
    "    'animal': 'Environmental and Road Conditions',\n",
    "    \n",
    "    'unable to determine': 'Unknown/Other',\n",
    "    'not applicable': 'Unknown/Other',\n",
    "    'related to bus stop': 'Unknown/Other',\n",
    "    'obstructed crosswalks': 'Unknown/Other',\n",
    "    \n",
    "    # Add the missing categories\n",
    "    'improper backing': 'Aggressive/Reckless Driving',\n",
    "    'equipment - vehicle condition': 'Driver\\'s Condition/Experience',\n",
    "    'disregarding other traffic signs': 'Aggressive/Reckless Driving',\n",
    "    'disregarding road markings': 'Aggressive/Reckless Driving',\n",
    "    'turning right on red': 'Aggressive/Reckless Driving'\n",
    "}\n",
    "\n",
    "# Apply the mapping to categorize the causes\n",
    "crashes_cleaned['crash_cause_category'] = crashes_cleaned['prim_contributory_cause'].map(cause_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d078502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Find unique values in 'prim_contributory_cause' that are not in the 'cause_mapping'\n",
    "missing_values = crashes_cleaned[~crashes_cleaned['prim_contributory_cause'].isin(cause_mapping.keys())]['prim_contributory_cause'].unique()\n",
    "\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "557f928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggressive/Reckless Driving          417688\n",
       "Unknown/Other                        400902\n",
       "Driver's Condition/Experience         51717\n",
       "Environmental and Road Conditions     19367\n",
       "Distraction                           11772\n",
       "Name: crash_cause_category, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts in the new category column\n",
    "crashes_cleaned['crash_cause_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7d7ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not applicable                                                                      371652\n",
       "unable to determine                                                                 324878\n",
       "failing to reduce speed to avoid crash                                               33161\n",
       "failing to yield right-of-way                                                        28925\n",
       "driving skills/knowledge/experience                                                  28101\n",
       "following too closely                                                                23735\n",
       "improper overtaking/passing                                                          14021\n",
       "improper lane usage                                                                  12692\n",
       "weather                                                                               9915\n",
       "improper turning/no signal                                                            9382\n",
       "improper backing                                                                      7194\n",
       "operating vehicle in erratic, reckless, careless, negligent or aggressive manner      5563\n",
       "disregarding traffic signals                                                          3659\n",
       "vision obscured (signs, tree limbs, buildings, etc.)                                  2794\n",
       "physical condition of driver                                                          2724\n",
       "distraction - from inside vehicle                                                     2689\n",
       "disregarding stop sign                                                                2605\n",
       "driving on wrong side/wrong way                                                       1899\n",
       "equipment - vehicle condition                                                         1826\n",
       "exceeding authorized speed limit                                                      1473\n",
       "distraction - from outside vehicle                                                    1465\n",
       "under the influence of alcohol/drugs (use when arrest is effected)                    1459\n",
       "exceeding safe speed for conditions                                                   1438\n",
       "had been drinking (use when arrest is not made)                                       1059\n",
       "road construction/maintenance                                                         1029\n",
       "disregarding other traffic signs                                                       915\n",
       "disregarding road markings                                                             883\n",
       "road engineering/surface/marking defects                                               834\n",
       "cell phone use other than texting                                                      674\n",
       "evasive action due to animal, object, nonmotorist                                      471\n",
       "related to bus stop                                                                    436\n",
       "animal                                                                                 427\n",
       "turning right on red                                                                   350\n",
       "distraction - other electronic device (navigation device, dvd player, etc.)            255\n",
       "bicycle advancing legally on red light                                                 231\n",
       "disregarding yield sign                                                                224\n",
       "texting                                                                                159\n",
       "obstructed crosswalks                                                                   98\n",
       "passing stopped school bus                                                              93\n",
       "motorcycle advancing legally on red light                                               58\n",
       "Name: sec_contributory_cause, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within sec_contributory_cause feature\n",
    "crashes_cleaned['sec_contributory_cause'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba5986",
   "metadata": {},
   "source": [
    "This feature is redundant to prim_contributory_cause, and a high majority of values are either 'not applicable' or 'unable to determine' so it will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee8084d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12/29/2020 05:00:00 pm    30\n",
       "11/10/2017 10:30:00 am    27\n",
       "02/17/2022 03:30:00 pm    21\n",
       "11/21/2024 10:30:00 am    20\n",
       "11/21/2024 10:00:00 am    20\n",
       "                          ..\n",
       "12/23/2016 12:41:00 pm     1\n",
       "10/03/2020 05:32:00 pm     1\n",
       "08/02/2021 05:15:00 pm     1\n",
       "01/08/2020 02:35:00 pm     1\n",
       "09/13/2023 01:08:00 pm     1\n",
       "Name: crash_date, Length: 592919, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_date feature\n",
    "crashes_cleaned['crash_date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b38fc",
   "metadata": {},
   "source": [
    "Will remove this feature. This information is captured in crash_hour, crash_day_of_the_week, crash_month. I keep the following three features and perform reclassification to help prepare for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6488deb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    69825\n",
       "16    68993\n",
       "17    67144\n",
       "14    60189\n",
       "18    55381\n",
       "13    54478\n",
       "12    52818\n",
       "8     47683\n",
       "11    45742\n",
       "9     41217\n",
       "10    40942\n",
       "19    40838\n",
       "7     38207\n",
       "20    33003\n",
       "21    29440\n",
       "22    27107\n",
       "23    23508\n",
       "0     19638\n",
       "6     19488\n",
       "1     16760\n",
       "2     14336\n",
       "5     12390\n",
       "3     11848\n",
       "4     10471\n",
       "Name: crash_hour, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_hour feature\n",
    "crashes_cleaned['crash_hour'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c99234c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    146122\n",
       "7    133158\n",
       "5    129717\n",
       "3    128456\n",
       "4    127880\n",
       "2    123620\n",
       "1    112493\n",
       "Name: crash_day_of_week, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_day_of_week feature\n",
    "crashes_cleaned['crash_day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "722e98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    86680\n",
       "9     82227\n",
       "8     80821\n",
       "7     78568\n",
       "11    78175\n",
       "6     77697\n",
       "5     77268\n",
       "12    74429\n",
       "3     67812\n",
       "4     66417\n",
       "1     66068\n",
       "2     65284\n",
       "Name: crash_month, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_month feature\n",
    "crashes_cleaned['crash_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3eae9995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crashes_cleaned['time_of_day'] = pd.cut(\n",
    "    crashes_cleaned['crash_hour'], \n",
    "    bins=[-1, 5, 11, 17, 23], \n",
    "    labels=['Night (Late)', 'Morning', 'Afternoon', 'Night (Early)'],\n",
    "    right=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "295b02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_cleaned['day_of_week'] = crashes_cleaned['crash_day_of_week'].replace({\n",
    "    1: 'Sun',\n",
    "    2: 'Mon',\n",
    "    3: 'Tues',\n",
    "    4: 'Wed',\n",
    "    5: 'Thur',\n",
    "    6: 'Fri',\n",
    "    7: 'Sat'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e914ee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fri     146122\n",
       "Sat     133158\n",
       "Thur    129717\n",
       "Tues    128456\n",
       "Wed     127880\n",
       "Mon     123620\n",
       "Sun     112493\n",
       "Name: day_of_week, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within day_of_week feature\n",
    "crashes_cleaned['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74963c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups crash_months into seasons and saves as new feature: season\n",
    "\n",
    "crashes_cleaned['season'] = pd.cut(\n",
    "    crashes_cleaned['crash_month'], \n",
    "    bins=[0, 2, 5, 8, 11, 12], \n",
    "    labels=['Winter', 'Spring', 'Summer', 'Fall', 'Winter'],\n",
    "    right=True,\n",
    "    ordered=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b54ef36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fall      247082\n",
       "Summer    237086\n",
       "Spring    211497\n",
       "Winter    205781\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within the new season feature\n",
    "crashes_cleaned['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0049afd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id                       0\n",
       "crash_date                            0\n",
       "posted_speed_limit                    0\n",
       "traffic_control_device                0\n",
       "device_condition                      0\n",
       "weather_condition                     0\n",
       "lighting_condition                    0\n",
       "first_crash_type                      0\n",
       "trafficway_type                       0\n",
       "lane_cnt                         702424\n",
       "alignment                             0\n",
       "roadway_surface_cond                  0\n",
       "road_defect                           0\n",
       "report_type                       28066\n",
       "crash_type                            0\n",
       "intersection_related_i           694392\n",
       "hit_and_run_i                    618754\n",
       "damage                                0\n",
       "date_police_notified                  0\n",
       "prim_contributory_cause               0\n",
       "sec_contributory_cause                0\n",
       "street_no                             0\n",
       "street_direction                      4\n",
       "street_name                           1\n",
       "beat_of_occurrence                    5\n",
       "num_units                             0\n",
       "most_severe_injury                 1993\n",
       "injuries_total                     1979\n",
       "injuries_fatal                     1979\n",
       "injuries_incapacitating            1979\n",
       "injuries_non_incapacitating        1979\n",
       "injuries_reported_not_evident      1979\n",
       "injuries_no_indication             1979\n",
       "injuries_unknown                   1979\n",
       "crash_hour                            0\n",
       "crash_day_of_week                     0\n",
       "crash_month                           0\n",
       "latitude                           6526\n",
       "longitude                          6526\n",
       "location                           6526\n",
       "speed_limit_category                  0\n",
       "traffic_control_category           1298\n",
       "road_category                         0\n",
       "severity_category                  1993\n",
       "crash_cause_category                  0\n",
       "time_of_day                           0\n",
       "day_of_week                           0\n",
       "season                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the count of null values within each feature\n",
    "crashes_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde9949",
   "metadata": {},
   "source": [
    "#### 2.1.8 Remove unuseful features: `.drop()` for list of features deemed not useful for analysis and store trimmed df as ‘crashes_cleaned’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acef48d",
   "metadata": {},
   "source": [
    "Domain knowledge and better understanding of the features and business problem led me to remove several features. Features dealing with aftermath, such as damage, and 'date_police_notified' both deal with aftermath, and thus do not offer much predictive insights, so they are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8fce1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_cleaned.drop(columns = [\n",
    "    'crash_date',\n",
    "    'hit_and_run_i',\n",
    "    'device_condition',\n",
    "    'weather_condition',\n",
    "    'road_defect',\n",
    "    'crash_type',\n",
    "    'damage',\n",
    "    'date_police_notified',\n",
    "    'sec_contributory_cause',\n",
    "    'street_no',\n",
    "    'report_type',\n",
    "    'beat_of_occurrence',\n",
    "    'num_units',\n",
    "    'alignment',\n",
    "    'injuries_total',\n",
    "    'injuries_fatal',\n",
    "     'injuries_incapacitating',\n",
    "     'injuries_non_incapacitating',\n",
    "     'injuries_reported_not_evident',\n",
    "     'injuries_no_indication',\n",
    "    'injuries_unknown',\n",
    "    'location',\n",
    "    'street_direction',\n",
    "    'lane_cnt', \n",
    "    'intersection_related_i',\n",
    "    'trafficway_type', \n",
    "    'crash_hour', \n",
    "    'crash_day_of_week', \n",
    "    'crash_month', \n",
    "    'posted_speed_limit', \n",
    "    'traffic_control_device', \n",
    "    'street_name', \n",
    "    'most_severe_injury',\n",
    "    'prim_contributory_cause',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'first_crash_type'\n",
    "], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d58d6b",
   "metadata": {},
   "source": [
    "#### 2.1.10 Convert data types: stored data types to reflect true data types (categorical variables as strings, numeric variables as int, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7055b736",
   "metadata": {},
   "source": [
    "Ensuring that features' stored data types match their true data type is another common cleaning step. Most of the features in the cleaned dataframe were categorical variables, so I saved them as 'category' data type. I could've also stored them as object types, but category types are easier to store and use less memory, which is important in contexts like this where you're dealing with such a vast amount of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bc6add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id               object\n",
       "lighting_condition          category\n",
       "roadway_surface_cond        category\n",
       "speed_limit_category        category\n",
       "traffic_control_category    category\n",
       "road_category               category\n",
       "severity_category           category\n",
       "crash_cause_category        category\n",
       "time_of_day                 category\n",
       "day_of_week                 category\n",
       "season                      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all the columns (except 'crash_record_id') to category type\n",
    "crashes_cleaned[[col for col in crashes_cleaned.columns if col != 'crash_record_id']] = crashes_cleaned[[col for col in crashes_cleaned.columns if col != 'crash_record_id']].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "crashes_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317101ca",
   "metadata": {},
   "source": [
    "Once datatypes were addressed and any unhelpful features removed, I checked the distribution of my target feature. I also had to decide how to handle the remaining null values. Since the remaining null values were such a small part of the total, I just decided to remove any row with a null value knowing that this would still leave me with plenty of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99ffda38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-serious    883394\n",
       "Serious         16059\n",
       "Name: severity_category, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of the target variable severity_category\n",
    "crashes_cleaned['severity_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58d9e1",
   "metadata": {},
   "source": [
    "Checking the distribution of my target, I can see there is significant class imbalance, and this will inform some of my future data preparation decisions. Right now I still have **16**k of my target class, but I will be cautious with removing rows as I want to make sure there are enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88ab5929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id             0.000000\n",
       "lighting_condition          0.000000\n",
       "roadway_surface_cond        0.000000\n",
       "speed_limit_category        0.000000\n",
       "traffic_control_category    0.143991\n",
       "road_category               0.000000\n",
       "severity_category           0.221089\n",
       "crash_cause_category        0.000000\n",
       "time_of_day                 0.000000\n",
       "day_of_week                 0.000000\n",
       "season                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks the percentage of null values within each feature\n",
    "(crashes_cleaned.isna().sum()/ len(crashes_cleaned))* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f829cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops any remaining rows that contain null values\n",
    "crashes_cleaned.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b5e16",
   "metadata": {},
   "source": [
    "With such small percentages of remaining null values I feel confident simply removing them as opposed to imputing values which could potentially introduce noise.\n",
    "\n",
    "The crashes_cleaned dataframe is now prepared for merging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d323b",
   "metadata": {},
   "source": [
    "### 2.2 People "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f873d",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* Steps:\n",
    "* **Preview Data**: `.head()`\n",
    "\n",
    "\n",
    "* **Understand Structure**: `.info()`\n",
    "\n",
    "\n",
    "* **Format Feature names and Row Values**: `.lower()`\n",
    "\n",
    "\n",
    "* **Drop features with overly high null values**: `.isna().sum()/ len(df)` for percentage of nulls for each feature\n",
    "\n",
    "\n",
    "* **Check for duplicates**: `.duplicated().sum()`\n",
    "\n",
    "\n",
    "* **inspect remaining features**: `.value_counts()`; \n",
    "\n",
    "    * make intentional decisions to keep or drop using `.value_counts()` distribution and domain knowledge; \n",
    "    * make note of any features to keep that will need cleaning/cardinality reduction/etc.\n",
    "\n",
    "\n",
    "* **remove unuseful features**: \n",
    "\n",
    "    * `.drop()` for list of features deemed not useful for analysis; \n",
    "    * store trimmed df as 'df_name_cleaned'\n",
    "\n",
    "\n",
    "* **Convert data types**: \n",
    "\n",
    "    * stored data types to reflect true data types \n",
    "    * (categorical variables as strings, numeric variables as int, ect.)\n",
    "\n",
    "\n",
    "* **reduce feature cardinality with label reclassification**:\n",
    "\n",
    "    * 'safety_equipment' to 'safety_equipment_category'\n",
    "    * 'age' to 'age_group'\n",
    " \n",
    " \n",
    "* **remove remaining nulls**: `.dropna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a1d85",
   "metadata": {},
   "source": [
    "#### 2.2.1 Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d47ba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>PERSON_TYPE</th>\n",
       "      <th>CRASH_RECORD_ID</th>\n",
       "      <th>VEHICLE_ID</th>\n",
       "      <th>CRASH_DATE</th>\n",
       "      <th>SEAT_NO</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>...</th>\n",
       "      <th>EMS_RUN_NO</th>\n",
       "      <th>DRIVER_ACTION</th>\n",
       "      <th>DRIVER_VISION</th>\n",
       "      <th>PHYSICAL_CONDITION</th>\n",
       "      <th>PEDPEDAL_ACTION</th>\n",
       "      <th>PEDPEDAL_VISIBILITY</th>\n",
       "      <th>PEDPEDAL_LOCATION</th>\n",
       "      <th>BAC_RESULT</th>\n",
       "      <th>BAC_RESULT VALUE</th>\n",
       "      <th>CELL_PHONE_USE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O749947</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>81dc0de2ed92aa62baccab641fa377be7feb1cc47e6554...</td>\n",
       "      <td>834816.0</td>\n",
       "      <td>09/28/2019 03:30:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60651</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST NOT OFFERED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O871921</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>af84fb5c8d996fcd3aefd36593c3a02e6e7509eeb27568...</td>\n",
       "      <td>827212.0</td>\n",
       "      <td>04/13/2020 10:50:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60620</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NOT OBSCURED</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST NOT OFFERED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O10018</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>71162af7bf22799b776547132ebf134b5b438dcf3dac6b...</td>\n",
       "      <td>9579.0</td>\n",
       "      <td>11/01/2015 05:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPROPER BACKING</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST NOT OFFERED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O10038</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>c21c476e2ccc41af550b5d858d22aaac4ffc88745a1700...</td>\n",
       "      <td>9598.0</td>\n",
       "      <td>11/01/2015 08:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST NOT OFFERED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O10039</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>eb390a4c8e114c69488f5fb8a097fe629f5a92fd528cf4...</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>11/01/2015 10:15:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST NOT OFFERED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PERSON_ID PERSON_TYPE                                    CRASH_RECORD_ID  \\\n",
       "0   O749947      DRIVER  81dc0de2ed92aa62baccab641fa377be7feb1cc47e6554...   \n",
       "1   O871921      DRIVER  af84fb5c8d996fcd3aefd36593c3a02e6e7509eeb27568...   \n",
       "2    O10018      DRIVER  71162af7bf22799b776547132ebf134b5b438dcf3dac6b...   \n",
       "3    O10038      DRIVER  c21c476e2ccc41af550b5d858d22aaac4ffc88745a1700...   \n",
       "4    O10039      DRIVER  eb390a4c8e114c69488f5fb8a097fe629f5a92fd528cf4...   \n",
       "\n",
       "   VEHICLE_ID              CRASH_DATE  SEAT_NO     CITY STATE ZIPCODE SEX  \\\n",
       "0    834816.0  09/28/2019 03:30:00 AM      NaN  CHICAGO    IL   60651   M   \n",
       "1    827212.0  04/13/2020 10:50:00 PM      NaN  CHICAGO    IL   60620   M   \n",
       "2      9579.0  11/01/2015 05:00:00 AM      NaN      NaN   NaN     NaN   X   \n",
       "3      9598.0  11/01/2015 08:00:00 AM      NaN      NaN   NaN     NaN   X   \n",
       "4      9600.0  11/01/2015 10:15:00 AM      NaN      NaN   NaN     NaN   X   \n",
       "\n",
       "   ...  EMS_RUN_NO     DRIVER_ACTION DRIVER_VISION PHYSICAL_CONDITION  \\\n",
       "0  ...         NaN           UNKNOWN       UNKNOWN            UNKNOWN   \n",
       "1  ...         NaN              NONE  NOT OBSCURED             NORMAL   \n",
       "2  ...         NaN  IMPROPER BACKING       UNKNOWN            UNKNOWN   \n",
       "3  ...         NaN           UNKNOWN       UNKNOWN            UNKNOWN   \n",
       "4  ...         NaN           UNKNOWN       UNKNOWN            UNKNOWN   \n",
       "\n",
       "  PEDPEDAL_ACTION PEDPEDAL_VISIBILITY PEDPEDAL_LOCATION        BAC_RESULT  \\\n",
       "0             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
       "1             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
       "2             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
       "3             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
       "4             NaN                 NaN               NaN  TEST NOT OFFERED   \n",
       "\n",
       "  BAC_RESULT VALUE CELL_PHONE_USE  \n",
       "0              NaN            NaN  \n",
       "1              NaN            NaN  \n",
       "2              NaN            NaN  \n",
       "3              NaN            NaN  \n",
       "4              NaN            NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previews the first 5 rows of the data\n",
    "people_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e633bc",
   "metadata": {},
   "source": [
    "#### 2.2.2 Understand Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6909a67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979859 entries, 0 to 1979858\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   PERSON_ID              object \n",
      " 1   PERSON_TYPE            object \n",
      " 2   CRASH_RECORD_ID        object \n",
      " 3   VEHICLE_ID             float64\n",
      " 4   CRASH_DATE             object \n",
      " 5   SEAT_NO                float64\n",
      " 6   CITY                   object \n",
      " 7   STATE                  object \n",
      " 8   ZIPCODE                object \n",
      " 9   SEX                    object \n",
      " 10  AGE                    float64\n",
      " 11  DRIVERS_LICENSE_STATE  object \n",
      " 12  DRIVERS_LICENSE_CLASS  object \n",
      " 13  SAFETY_EQUIPMENT       object \n",
      " 14  AIRBAG_DEPLOYED        object \n",
      " 15  EJECTION               object \n",
      " 16  INJURY_CLASSIFICATION  object \n",
      " 17  HOSPITAL               object \n",
      " 18  EMS_AGENCY             object \n",
      " 19  EMS_RUN_NO             object \n",
      " 20  DRIVER_ACTION          object \n",
      " 21  DRIVER_VISION          object \n",
      " 22  PHYSICAL_CONDITION     object \n",
      " 23  PEDPEDAL_ACTION        object \n",
      " 24  PEDPEDAL_VISIBILITY    object \n",
      " 25  PEDPEDAL_LOCATION      object \n",
      " 26  BAC_RESULT             object \n",
      " 27  BAC_RESULT VALUE       float64\n",
      " 28  CELL_PHONE_USE         object \n",
      "dtypes: float64(4), object(25)\n",
      "memory usage: 438.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# provides info about the dataframe\n",
    "people_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e6216a",
   "metadata": {},
   "source": [
    "#### 2.2.3 Format Feature names and Row Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad38e90",
   "metadata": {},
   "source": [
    "Initial observations after previewing the first 5 rows and the dataframe structure with `.info()` are that this dataset is massive with nearly 2 million records. Extensive cleaning will need to take place to reduce the size of this dataset for computational efficiency. \n",
    "\n",
    "For a first step, I decided to make the feature names lower case simply for readability, and as a precuror cleaning step I made all string values lower case in the hopes that this may deal with some misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cd2ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts all feature names to lower case\n",
    "people_df.columns = people_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e523e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string values in object columns to lowercase\n",
    "for col in people_df.select_dtypes(include='object').columns:\n",
    "    people_df[col] = people_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd2d57",
   "metadata": {},
   "source": [
    "#### 2.2.4 Drop features with overly high null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bd9e9",
   "metadata": {},
   "source": [
    "#### 2.1.4 Drop features with overly high null values: \n",
    "\n",
    "While there are a lot of records in this dataframe, some features also have a lot of null values.  I know that features with a significant majority of null values will not be helpful for analysis so I start by trying to identify these features and remove them right off the bat. Rather than look at the count of nulls, I used `(.isna().sum()/ len(df)) *100` to get the percentage of nulls for each feature. This is easier to grasp than null counts in the 10 and hundred thousands. \n",
    "\n",
    "For quick cleaning, I chose a 90% null threshold to automatically remove features. For the features with between less than 90% nulls, I decided to inspect them more closely before blinding removing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ea6643c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id                 0.00\n",
       "person_type               0.00\n",
       "crash_record_id           0.00\n",
       "vehicle_id                2.05\n",
       "crash_date                0.00\n",
       "seat_no                  79.78\n",
       "city                     27.23\n",
       "state                    26.13\n",
       "zipcode                  33.05\n",
       "sex                       1.68\n",
       "age                      29.11\n",
       "drivers_license_state    41.46\n",
       "drivers_license_class    51.34\n",
       "safety_equipment          0.28\n",
       "airbag_deployed           1.98\n",
       "ejection                  1.26\n",
       "injury_classification     0.04\n",
       "hospital                 83.81\n",
       "ems_agency               90.01\n",
       "ems_run_no               98.33\n",
       "driver_action            20.40\n",
       "driver_vision            20.43\n",
       "physical_condition       20.34\n",
       "pedpedal_action          98.04\n",
       "pedpedal_visibility      98.04\n",
       "pedpedal_location        98.04\n",
       "bac_result               20.35\n",
       "bac_result value         99.89\n",
       "cell_phone_use           99.94\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the percentage of null values per feature, rounded to 2 places\n",
    "round((people_df.isna().sum()/ len(people_df)*100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10d5eeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ems_agency',\n",
       " 'ems_run_no',\n",
       " 'pedpedal_action',\n",
       " 'pedpedal_visibility',\n",
       " 'pedpedal_location',\n",
       " 'bac_result value',\n",
       " 'cell_phone_use']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting all features with 90% or more of its values are null and stores features as a list\n",
    "ppl_high_null_features = list(people_df.columns[(people_df.isna().sum() / len(people_df) * 100) >= 90])\n",
    "ppl_high_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c17b7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979859 entries, 0 to 1979858\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   person_id              object \n",
      " 1   person_type            object \n",
      " 2   crash_record_id        object \n",
      " 3   vehicle_id             float64\n",
      " 4   crash_date             object \n",
      " 5   seat_no                float64\n",
      " 6   city                   object \n",
      " 7   state                  object \n",
      " 8   zipcode                object \n",
      " 9   sex                    object \n",
      " 10  age                    float64\n",
      " 11  drivers_license_state  object \n",
      " 12  drivers_license_class  object \n",
      " 13  safety_equipment       object \n",
      " 14  airbag_deployed        object \n",
      " 15  ejection               object \n",
      " 16  injury_classification  object \n",
      " 17  hospital               object \n",
      " 18  driver_action          object \n",
      " 19  driver_vision          object \n",
      " 20  physical_condition     object \n",
      " 21  bac_result             object \n",
      "dtypes: float64(3), object(19)\n",
      "memory usage: 332.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# drops all features with 90% or more null values\n",
    "people_cleaned = people_df.drop(columns=ppl_high_null_features)\n",
    "people_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a2713",
   "metadata": {},
   "source": [
    "#### 2.2.5 deleting people from memory\n",
    "\n",
    "Once I created a new dataframe by dropping the features with high null counts, I no longer needed the original people_df dataset so I deleted it from memory due to its large size and ability to take up a large amount of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d9f701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes the people_df dataframe to clear up memory\n",
    "\n",
    "del people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18013df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa257ff",
   "metadata": {},
   "source": [
    "#### 2.2.6 Checking for duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13800a6a",
   "metadata": {},
   "source": [
    "This data set has 3 different ID features, so to get a better sense of what each feature and row represent I calculated the number of rows that contain duplicates for the three id features to better understand how this dataset relates to the crashes and vehicles dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6bce1df7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate person_id rows: 0\n",
      "\n",
      "==================================================\n",
      "Number of duplicate crash_record_id rows: 1080392\n",
      "Example duplicate rows for crash_record_id:\n",
      "   person_id person_type                                    crash_record_id  \\\n",
      "17   o879680      driver  49336aaca932f7935c361c892d31e01360a08133079e3a...   \n",
      "38   o848629      driver  0471d392a958a0fabaed931ee563b8228cedce40c426ba...   \n",
      "45  o1304797      driver  bca52a367d2f053f3a338c9199261b11b245fb00db3b9e...   \n",
      "56   o848685      driver  1f86bcd0d38e41c44373a0b3197669ad39625c8d028f28...   \n",
      "58   o848687      driver  91069a7cfa1cec819cbf4c40c6da6859dc3508c324748c...   \n",
      "\n",
      "    vehicle_id              crash_date  seat_no     city state zipcode sex  \\\n",
      "17    834560.0  05/05/2020 12:20:00 pm      NaN  chicago    il   60641   f   \n",
      "38    805363.0  02/23/2020 06:22:00 pm      NaN  chicago    il   60649   f   \n",
      "45   1239154.0  03/25/2022 05:10:00 am      NaN  chicago    il   60651   m   \n",
      "56    805438.0  02/21/2020 05:00:00 pm      NaN  chicago    il   60639   f   \n",
      "58    805410.0  02/23/2020 08:53:00 pm      NaN  chicago    il   60644   m   \n",
      "\n",
      "    ...  drivers_license_class  safety_equipment     airbag_deployed ejection  \\\n",
      "17  ...                      d  safety belt used      not applicable     none   \n",
      "38  ...                      d     usage unknown      did not deploy     none   \n",
      "45  ...                      d  safety belt used      did not deploy     none   \n",
      "56  ...                      d     usage unknown  deployment unknown     none   \n",
      "58  ...                      d     usage unknown     deployed, front     none   \n",
      "\n",
      "      injury_classification hospital driver_action driver_vision  \\\n",
      "17  no indication of injury      NaN          none  not obscured   \n",
      "38    reported, not evident      NaN       unknown  not obscured   \n",
      "45  no indication of injury      NaN          none  not obscured   \n",
      "56  no indication of injury      NaN       unknown       unknown   \n",
      "58  no indication of injury      NaN          none  not obscured   \n",
      "\n",
      "   physical_condition        bac_result  \n",
      "17             normal  test not offered  \n",
      "38             normal  test not offered  \n",
      "45             normal  test not offered  \n",
      "56            unknown  test not offered  \n",
      "58             normal  test not offered  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "==================================================\n",
      "Number of duplicate vehicle_id rows: 421011\n",
      "Example duplicate rows for vehicle_id:\n",
      "    person_id person_type                                    crash_record_id  \\\n",
      "238   o838089  pedestrian  70cee122a09d5a638b82ebfa7c32d75de4c932b168b5aa...   \n",
      "240   o838091  pedestrian  064ec5501d5416ee5b6eeec1d6d839adf9f17d642ca6e8...   \n",
      "245   o838099  pedestrian  b473e527a0648000f430177e0bc0968ea7d87f55a14aaf...   \n",
      "307   o838234  pedestrian  d14abcac0d5211556093b27f866291121caa2f50c6b71b...   \n",
      "374   o838337     bicycle  03204df22743eb4559749b8e3966c471a544228aa0fe9c...   \n",
      "\n",
      "     vehicle_id              crash_date  seat_no         city state zipcode  \\\n",
      "238         NaN  02/08/2020 10:59:00 am      NaN      chicago    il   60630   \n",
      "240         NaN  02/08/2020 09:52:00 am      NaN  tinley park    il     NaN   \n",
      "245         NaN  02/08/2020 12:01:00 pm      NaN      chicago    il   60652   \n",
      "307         NaN  02/08/2020 01:25:00 pm      NaN      chicago    il     NaN   \n",
      "374         NaN  02/08/2020 05:04:00 pm      NaN      chicago    il   60628   \n",
      "\n",
      "    sex  ...  drivers_license_class safety_equipment airbag_deployed  \\\n",
      "238   m  ...                    NaN     none present             NaN   \n",
      "240   m  ...                    NaN     none present             NaN   \n",
      "245   f  ...                    NaN     none present             NaN   \n",
      "307   m  ...                    NaN              NaN             NaN   \n",
      "374   f  ...                    NaN  helmet not used             NaN   \n",
      "\n",
      "            ejection     injury_classification                   hospital  \\\n",
      "238              NaN     reported, not evident                        NaN   \n",
      "240              NaN  nonincapacitating injury                        NaN   \n",
      "245              NaN  nonincapacitating injury    northwestern university   \n",
      "307              NaN     incapacitating injury  comer children's hospital   \n",
      "374  totally ejected  nonincapacitating injury                        NaN   \n",
      "\n",
      "    driver_action driver_vision physical_condition        bac_result  \n",
      "238         other       unknown             normal  test not offered  \n",
      "240          none  not obscured             normal  test not offered  \n",
      "245          none  not obscured             normal  test not offered  \n",
      "307          none       unknown            unknown  test not offered  \n",
      "374          none  not obscured             normal  test not offered  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the list of ID columns to check for duplicates\n",
    "id_columns = ['person_id', 'crash_record_id', 'vehicle_id']\n",
    "\n",
    "# Loop through each column to check for duplicates\n",
    "for column in id_columns:\n",
    "    # Directly calculate and print the count of duplicates\n",
    "    duplicates_count = people_cleaned[column].duplicated().sum()\n",
    "    print(f\"Number of duplicate {column} rows: {duplicates_count}\")\n",
    "\n",
    "    # If needed, display duplicate rows (uncommon for large datasets due to memory concerns)\n",
    "    if duplicates_count > 0:\n",
    "        print(f\"Example duplicate rows for {column}:\")\n",
    "        print(people_cleaned[people_cleaned[column].duplicated()].head())  # Show only the first few rows\n",
    "    print(\"\\n\" + \"=\"*50)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8aba45",
   "metadata": {},
   "source": [
    "##### Explanation of Output:\n",
    "\n",
    "1. **Duplicate person_id Rows:**\n",
    "   - No duplicate person_id rows were found, which means each person_id is unique in this dataset.\n",
    "\n",
    "2. **Duplicate crash_record_id Rows:**\n",
    "   - A total of 1,080,392 rows are duplicates based on crash_record_id. This suggests that multiple individuals (drivers, passengers, etc.) may have been associated with the same crash. This is expected if there are multiple people involved in the same crash event.\n",
    "\n",
    "3. **Duplicate vehicle_id Rows:**\n",
    "   - A total of 421,011 rows are duplicates based on vehicle_id. This indicates that some vehicles appear in multiple records, potentially due to different passengers or crashes involving the same vehicle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa2612",
   "metadata": {},
   "source": [
    "#### 2.2.7 Inspect remaining features\n",
    "\n",
    "Once columns with high null values were taken care of, I used `.value_counts()` to inspect many of the remaining columns to look for things like cardianlity, misspelling, class labels, stored data types, etc. I used some domain knowledge to avoid looking through every single feature. Similar to my process in the traffic_crashes dataframe, some for useful features with potentially unclear labels or a high cardinality, reclassify feature labels into less, more easily understandable labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e1f295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driver                 1539401\n",
       "passenger               400333\n",
       "pedestrian               23417\n",
       "bicycle                  14716\n",
       "non-motor vehicle         1665\n",
       "non-contact vehicle        327\n",
       "Name: person_type, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['person_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e489252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12/29/2020 05:00:00 pm    72\n",
       "11/10/2017 10:30:00 am    64\n",
       "03/16/2018 10:17:00 am    61\n",
       "08/21/2024 01:45:00 am    56\n",
       "06/22/2019 06:15:00 pm    55\n",
       "                          ..\n",
       "11/21/2023 11:50:00 pm     1\n",
       "08/20/2023 01:44:00 pm     1\n",
       "06/26/2022 08:35:00 pm     1\n",
       "08/04/2018 10:55:00 am     1\n",
       "07/07/2019 09:46:00 pm     1\n",
       "Name: crash_date, Length: 591866, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['crash_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07f775e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0     193103\n",
       "6.0      67158\n",
       "4.0      53319\n",
       "5.0      18870\n",
       "1.0      17966\n",
       "2.0      16957\n",
       "12.0     10605\n",
       "7.0       9259\n",
       "10.0      9017\n",
       "11.0      3548\n",
       "8.0        531\n",
       "Name: seat_no, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['seat_no'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8bd1877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usage unknown                                 0.476501\n",
       "safety belt used                              0.464880\n",
       "none present                                  0.033816\n",
       "safety belt not used                          0.005434\n",
       "helmet not used                               0.005104\n",
       "child restraint used                          0.003962\n",
       "child restraint - forward facing              0.002597\n",
       "bicycle helmet (pedacyclist involved only)    0.002004\n",
       "child restraint - type unknown                0.001373\n",
       "child restraint - rear facing                 0.001190\n",
       "dot compliant motorcycle helmet               0.000802\n",
       "helmet used                                   0.000688\n",
       "booster seat                                  0.000678\n",
       "child restraint not used                      0.000437\n",
       "not dot compliant motorcycle helmet           0.000157\n",
       "should/lap belt used improperly               0.000145\n",
       "wheelchair                                    0.000123\n",
       "child restraint used improperly               0.000085\n",
       "stretcher                                     0.000024\n",
       "Name: safety_equipment, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['safety_equipment'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbd9c1",
   "metadata": {},
   "source": [
    "Could be an important predictor, but need to reduce cardinality. In the cell below, I reclassify the `safety_equipment` labels into 4 interpretable classes. This reclassification helps reduce cardinality which will be helpful during OneHotEncoding and improve computation efficiency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e736d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the original 'safety_equipment' values to broader categories\n",
    "safety_equipment_mapping = {\n",
    "    # Used Equipment\n",
    "    'safety belt used': 'Used',\n",
    "    'child restraint used': 'Used',\n",
    "    'child restraint - forward facing': 'Used',\n",
    "    'bicycle helmet (pedacyclist involved only)': 'Used',\n",
    "    'child restraint - type unknown': 'Used',\n",
    "    'child restraint - rear facing': 'Used',\n",
    "    'dot compliant motorcycle helmet': 'Used',\n",
    "    'helmet used': 'Used',\n",
    "    'booster seat': 'Used',\n",
    "    'child restraint used improperly': 'Used',\n",
    "\n",
    "    # Not Used Equipment\n",
    "    'safety belt not used': 'Not Used',\n",
    "    'helmet not used': 'Not Used',\n",
    "    'child restraint not used': 'Not Used',\n",
    "    'not dot compliant motorcycle helmet': 'Not Used',\n",
    "    'should/lap belt used improperly': 'Not Used',\n",
    "\n",
    "    # Unknown Equipment Usage\n",
    "    'usage unknown': 'Unknown',\n",
    "\n",
    "    # Other/Special Case Equipment\n",
    "    'none present': 'Other/Special Case', \n",
    "    'wheelchair': 'Other/Special Case',\n",
    "    'stretcher': 'Other/Special Case',\n",
    "    \n",
    "    # Catch-all for any unknown or missing values\n",
    "    'unknown': 'Other/Special Case',  \n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'safety_equipment' column\n",
    "people_cleaned['safety_equipment_category'] = people_cleaned['safety_equipment'].map(safety_equipment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6daa2b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Used                  0.478260\n",
       "Unknown               0.476501\n",
       "Other/Special Case    0.033962\n",
       "Not Used              0.011277\n",
       "Name: safety_equipment_category, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts for the new grouped categories\n",
    "people_cleaned['safety_equipment_category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845385e9",
   "metadata": {},
   "source": [
    "Based on this output, even after recategorization, this feature will not be very useful. About 95% of the data is split between \"used\" and \"unknown\", with the remaining 5% split between \"other/special case\" and \"not used\". I will drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae40e3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "did not deploy                            987711\n",
       "not applicable                            424194\n",
       "deployment unknown                        397461\n",
       "deployed, front                            61565\n",
       "deployed, combination                      50895\n",
       "deployed, side                             17944\n",
       "deployed other (knee, air, belt, etc.)       973\n",
       "Name: airbag_deployed, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['airbag_deployed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43450826",
   "metadata": {},
   "source": [
    "This feature might be more helpful if we simply knew: did the airbag deploy or not? In the cell below, I reclassify the `airbag_deployed` labels into 3 interpretable classes. This reclassification helps reduce cardinality which will be helpful during OneHotEncoding and improve computation efficiency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3d3450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for airbag_deployed\n",
    "airbag_mapping = {\n",
    "    'did not deploy': 'Not Deployed',\n",
    "    'not applicable': 'Not Deployed',  # Assuming \"not applicable\" should be considered as unknown\n",
    "    'deployment unknown': 'Unknown',\n",
    "    'deployed, front': 'Deployed',\n",
    "    'deployed, combination': 'Deployed',\n",
    "    'deployed, side': 'Deployed',\n",
    "    'deployed other (knee, air, belt, etc.)': 'Deployed'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'airbag_deployed' column\n",
    "people_cleaned['airbag_deployed'] = people_cleaned['airbag_deployed'].map(airbag_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a53e35b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Deployed    1411905\n",
       "Unknown          397461\n",
       "Deployed         131377\n",
       "Name: airbag_deployed, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the new feature's value counts\n",
    "people_cleaned['airbag_deployed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01978d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                  1820806\n",
       "unknown                125622\n",
       "totally ejected          5904\n",
       "partially ejected        1449\n",
       "trapped/extricated       1196\n",
       "Name: ejection, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['ejection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a14adf",
   "metadata": {},
   "source": [
    "This feature might be normally be helpful, but it is far too skewed to be helpful for this analysis. It contains about 8.5k values other than 'none' or 'unknown'. This will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b0e67d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no indication of injury     1803602\n",
       "nonincapacitating injury      98271\n",
       "reported, not evident         58267\n",
       "incapacitating injury         17878\n",
       "fatal                          1089\n",
       "Name: injury_classification, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['injury_classification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de752196",
   "metadata": {},
   "source": [
    "We can drop this. It contains similar information to 'most_severe_injury' but is more imbalanced so I will drop it and keep 'most_severe_injury' as my target. This decision is aided by the fact that for this project I am focused more on crash-level data, than people-level data. Simply, I want to focus on which crashes resulted in serious injury, more general than which people were seriously injured. So while I could compute this with injury_classification, most_severe_injury already describes what I'm analyzing and thus will require less target feature preparation than if I chose to use injury_classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d09a573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                                 0.36\n",
       "unknown                              0.25\n",
       "failed to yield                      0.09\n",
       "other                                0.09\n",
       "followed too closely                 0.06\n",
       "improper backing                     0.03\n",
       "improper turn                        0.03\n",
       "improper lane change                 0.03\n",
       "improper passing                     0.02\n",
       "disregarded control devices          0.02\n",
       "too fast for conditions              0.01\n",
       "wrong way/side                       0.00\n",
       "improper parking                     0.00\n",
       "overcorrected                        0.00\n",
       "evading police vehicle               0.00\n",
       "cell phone use other than texting    0.00\n",
       "emergency vehicle on call            0.00\n",
       "texting                              0.00\n",
       "stopped school bus                   0.00\n",
       "license restrictions                 0.00\n",
       "Name: driver_action, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints class distribution percentages of driver_action, rounded to 2 places\n",
    "round(people_cleaned['driver_action'].value_counts(normalize = True), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951122ed",
   "metadata": {},
   "source": [
    "This feature is similar to 'prim_contributory_cause' in crashes, but this one contains 20% nulls. Will drop this and keep prim_contributory_cause instead to avoid multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dee9c509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not obscured              784184\n",
       "unknown                   753832\n",
       "other                      15389\n",
       "moving vehicles             8800\n",
       "parked vehicles             5429\n",
       "windshield (water/ice)      4169\n",
       "blinded - sunlight          1879\n",
       "trees, plants                614\n",
       "buildings                    558\n",
       "blinded - headlights         168\n",
       "blowing materials            108\n",
       "hillcrest                    102\n",
       "embankment                    85\n",
       "signboard                     38\n",
       "Name: driver_vision, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['driver_vision'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87957d",
   "metadata": {},
   "source": [
    "This feature is too skewed to provide any real analytical benefit. The top two classes by 500k values are 'not_obscured' and 'unknown', so I will drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f321380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal                          1020511\n",
       "unknown                          527441\n",
       "impaired - alcohol                 6635\n",
       "removed by ems                     5697\n",
       "other                              4585\n",
       "emotional                          4213\n",
       "fatigued/asleep                    4108\n",
       "illness/fainted                    1408\n",
       "had been drinking                  1128\n",
       "impaired - drugs                    726\n",
       "impaired - alcohol and drugs        416\n",
       "medicated                           193\n",
       "Name: physical_condition, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['physical_condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbcc3b",
   "metadata": {},
   "source": [
    "Most classes here are 'normal' or 'unknown' which is not particularly insightful, so I will remove this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7b150eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test not offered                   1554246\n",
       "test refused                         16163\n",
       "test performed, results unknown       3715\n",
       "test taken                            2784\n",
       "Name: bac_result, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['bac_result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39cca8",
   "metadata": {},
   "source": [
    "Most values are 'test not offered' and 'test refused'. Again, not very insightful, so I will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6432d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m    1023595\n",
       "f     743117\n",
       "x     179808\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46f80e",
   "metadata": {},
   "source": [
    "This feature could be insightful. Will change the label names to be more descriptive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8c2254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'other', 'female', nan], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the values in the 'sex' feature\n",
    "people_cleaned['sex'] = people_cleaned['sex'].replace({'m': 'male', 'f': 'female', 'x': 'other'})\n",
    "\n",
    "# Verify the changes\n",
    "people_cleaned['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "491bd06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 26.0     39239\n",
       " 25.0     39229\n",
       " 27.0     39187\n",
       " 28.0     38579\n",
       " 24.0     38031\n",
       "          ...  \n",
       "-40.0         1\n",
       "-177.0        1\n",
       "-49.0         1\n",
       "-47.0         1\n",
       "-59.0         1\n",
       "Name: age, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the distribution of values within crash_type feature\n",
    "people_cleaned['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bb898",
   "metadata": {},
   "source": [
    "This information could be interesting to investigate and feels like it could be an insightful predictor, but its high cardinality means it will need some reclassifying in order to best be insightful. I chose to reclassify this based on age group, focusing on delineating between ages too young to drive **<16** years old, ages that are eligible to drive but brains are not fully developed (**16-26**), ages of fully developed adult brains (**27-65**), and then older folks (**65+**). I am hopeful that these labels will provide more insight than the original labels and help improve computational efficiency during modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22754d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age age_group\n",
      "0  25.0     16-26\n",
      "1  37.0     27-65\n",
      "2   NaN       NaN\n",
      "3   NaN       NaN\n",
      "4   NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Sample data (replace with your actual DataFrame)\n",
    "age_bins_df = pd.DataFrame({\n",
    "    'age': [5, 15, 16, 25, 30, 60, 100, 120, -5, 200]\n",
    "})\n",
    "\n",
    "# Define the bins for age groups\n",
    "age_bins = [1, 16, 27, 66, 115]\n",
    "\n",
    "# Labels for the age groups\n",
    "age_labels = ['1-15', '16-26', '27-65', '65+']  \n",
    "\n",
    "# Apply corrections for age values outside the valid range (negative, 0, or greater than 115)\n",
    "people_cleaned['age'] = people_cleaned['age'].apply(lambda x: np.nan if x < 1 or x > 115 else x)\n",
    "\n",
    "# Apply pd.cut() to create a new 'age_group' column\n",
    "people_cleaned['age_group'] = pd.cut(people_cleaned['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Print the first few rows to verify the new grouping\n",
    "print(people_cleaned[['age', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6d82e",
   "metadata": {},
   "source": [
    "#### 2.2.8 remove unuseful features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964bf7d",
   "metadata": {},
   "source": [
    "Using domain knowledge and understanding of the business problem and target varaible, I decided several features such as drivers license state and class are not relevant, so I dropped them. After all was said and done with feature removal, the remaining dataset had 4 features, one of which was the secondary key: crash_record_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e7895c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1979859 entries, 0 to 1979858\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Dtype   \n",
      "---  ------           -----   \n",
      " 0   crash_record_id  object  \n",
      " 1   sex              object  \n",
      " 2   airbag_deployed  object  \n",
      " 3   age_group        category\n",
      "dtypes: category(1), object(3)\n",
      "memory usage: 47.2+ MB\n"
     ]
    }
   ],
   "source": [
    "people_cleaned.drop(columns=['person_id',\n",
    "                      'person_type',\n",
    "                      'vehicle_id',\n",
    "                      'drivers_license_state', \n",
    "                      'drivers_license_class',\n",
    "                      'city', \n",
    "                      'state', \n",
    "                      'zipcode',\n",
    "                      'hospital', \n",
    "                      'crash_date',\n",
    "                      'seat_no',\n",
    "                      'ejection',\n",
    "                      'injury_classification',\n",
    "                      'driver_vision',\n",
    "                      'driver_action',\n",
    "                      'physical_condition',\n",
    "                      'bac_result',\n",
    "                      'age', \n",
    "                      'safety_equipment',\n",
    "                      'safety_equipment_category'\n",
    "                     ], inplace = True)\n",
    "people_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2866175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the specified columns to category type\n",
    "people_cleaned[['age_group', 'airbag_deployed', 'sex']] = people_cleaned[['age_group', 'airbag_deployed', 'sex']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "527c2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id     0.000000\n",
       "sex                 1.683908\n",
       "airbag_deployed     1.975696\n",
       "age_group          29.891624\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints the percentages of null values within each feature\n",
    "(people_cleaned.isna().sum()/ len(people_cleaned)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ee5e9",
   "metadata": {},
   "source": [
    "By printing the percentage of null values in the remaining columns I see that sex and airbag_deployed only have a small percentage of null values, while age_group has almost 15 times more. Despite this, age_group still contains a majority of non-null values. With the dataset now containing nearly 2 million records, I feel fine simply dropping all rows with null values, as I will still have plenty of data to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "763b72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops all rows with null values\n",
    "people_cleaned.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26282d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id    0\n",
       "sex                0\n",
       "airbag_deployed    0\n",
       "age_group          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirms that cleaning of this dataset is complete\n",
    "people_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a648a",
   "metadata": {},
   "source": [
    "With zero null values in each of 4 features, next up I will need to aggregate this data to help with merging the three datasets. I will provide further justifications for aggregations and my merging process further along in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5569469",
   "metadata": {},
   "source": [
    "### 2.3 Vehicles\n",
    "\n",
    "2.3.4 Drop features with overly high null values\n",
    "\n",
    "2.3.5 Check for duplicates\n",
    "\n",
    "2.3.6 inspect remaining features\n",
    "\n",
    "2.3.6.1 reduce feature cardinality with bucketing\n",
    "\n",
    "2.3.7 remove unuseful features\n",
    "\n",
    "2.3.8 Convert data types\n",
    "\n",
    "2.3.9 remove remaining nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a174cb",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "* Steps:\n",
    "* **Preview Data**: `.head()`\n",
    "\n",
    "\n",
    "* **Understand Structure**: `.info()`\n",
    "\n",
    "\n",
    "* **Format Feature names and Row Values**: `.lower()`\n",
    "\n",
    "\n",
    "* **Drop features with overly high null values**: `.isna().sum()/ len(df)` for percentage of nulls for each feature\n",
    "\n",
    "\n",
    "* **Check for duplicates**: `.duplicated().sum()`\n",
    "\n",
    "\n",
    "* **inspect remaining features**: `.value_counts()`; \n",
    "\n",
    "    * make intentional decisions to keep or drop using `.value_counts()` distribution and domain knowledge; \n",
    "    * make note of any features to keep that will need cleaning/cardinality reduction/etc.\n",
    "\n",
    "\n",
    "* **remove unuseful features**: \n",
    "\n",
    "    * `.drop()` for list of features deemed not useful for analysis; \n",
    "    * store trimmed df as 'df_name_cleaned'\n",
    "\n",
    "\n",
    "* **reduce feature cardinality with label reclassification**:\n",
    "\n",
    "    * 'safety_equipment' to 'safety_equipment_category'\n",
    "    * 'age' to 'age_group'\n",
    " \n",
    " \n",
    "* **Convert data types**: \n",
    "\n",
    "    * stored data types to reflect true data types \n",
    "    * (text as string, categorical variables as categories, numeric variables as int, ect.) \n",
    " \n",
    "* **remove remaining nulls**: `.dropna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586b197",
   "metadata": {},
   "source": [
    "#### 2.3.1 Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3b7902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH_UNIT_ID</th>\n",
       "      <th>CRASH_RECORD_ID</th>\n",
       "      <th>CRASH_DATE</th>\n",
       "      <th>UNIT_NO</th>\n",
       "      <th>UNIT_TYPE</th>\n",
       "      <th>NUM_PASSENGERS</th>\n",
       "      <th>VEHICLE_ID</th>\n",
       "      <th>CMRC_VEH_I</th>\n",
       "      <th>MAKE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAILER1_LENGTH</th>\n",
       "      <th>TRAILER2_LENGTH</th>\n",
       "      <th>TOTAL_VEHICLE_LENGTH</th>\n",
       "      <th>AXLE_CNT</th>\n",
       "      <th>VEHICLE_CONFIG</th>\n",
       "      <th>CARGO_BODY_TYPE</th>\n",
       "      <th>LOAD_TYPE</th>\n",
       "      <th>HAZMAT_OUT_OF_SERVICE_I</th>\n",
       "      <th>MCS_OUT_OF_SERVICE_I</th>\n",
       "      <th>HAZMAT_CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1717556</td>\n",
       "      <td>7b1763088507f77e0e552c009a6bf89a4d6330c7527706...</td>\n",
       "      <td>12/06/2023 03:24:00 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1634931.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>SENTRA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1717574</td>\n",
       "      <td>2603ff5a88f0b9b54576934c5ed4e4a64e8278e005687b...</td>\n",
       "      <td>12/06/2023 04:00:00 PM</td>\n",
       "      <td>2</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1634978.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>SEBRING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1717579</td>\n",
       "      <td>a52ef70e33d468b855b5be44e8638a564434dcf99c0edf...</td>\n",
       "      <td>12/06/2023 04:30:00 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1634948.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBARU</td>\n",
       "      <td>OUTBACK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1720118</td>\n",
       "      <td>609055f4b1a72a44d6ec40ba9036cefd7c1287a755eb6c...</td>\n",
       "      <td>12/10/2023 12:12:00 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1637401.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>RAV4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1720119</td>\n",
       "      <td>609055f4b1a72a44d6ec40ba9036cefd7c1287a755eb6c...</td>\n",
       "      <td>12/10/2023 12:12:00 PM</td>\n",
       "      <td>2</td>\n",
       "      <td>DRIVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1637408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUBARU</td>\n",
       "      <td>OUTBACK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH_UNIT_ID                                    CRASH_RECORD_ID  \\\n",
       "0        1717556  7b1763088507f77e0e552c009a6bf89a4d6330c7527706...   \n",
       "1        1717574  2603ff5a88f0b9b54576934c5ed4e4a64e8278e005687b...   \n",
       "2        1717579  a52ef70e33d468b855b5be44e8638a564434dcf99c0edf...   \n",
       "3        1720118  609055f4b1a72a44d6ec40ba9036cefd7c1287a755eb6c...   \n",
       "4        1720119  609055f4b1a72a44d6ec40ba9036cefd7c1287a755eb6c...   \n",
       "\n",
       "               CRASH_DATE  UNIT_NO UNIT_TYPE  NUM_PASSENGERS  VEHICLE_ID  \\\n",
       "0  12/06/2023 03:24:00 PM        1    DRIVER             NaN   1634931.0   \n",
       "1  12/06/2023 04:00:00 PM        2    DRIVER             NaN   1634978.0   \n",
       "2  12/06/2023 04:30:00 PM        1    DRIVER             NaN   1634948.0   \n",
       "3  12/10/2023 12:12:00 PM        1    DRIVER             NaN   1637401.0   \n",
       "4  12/10/2023 12:12:00 PM        2    DRIVER             NaN   1637408.0   \n",
       "\n",
       "  CMRC_VEH_I      MAKE    MODEL  ... TRAILER1_LENGTH  TRAILER2_LENGTH  \\\n",
       "0        NaN    NISSAN   SENTRA  ...             NaN              NaN   \n",
       "1        NaN  CHRYSLER  SEBRING  ...             NaN              NaN   \n",
       "2        NaN    SUBARU  OUTBACK  ...             NaN              NaN   \n",
       "3        NaN    TOYOTA     RAV4  ...             NaN              NaN   \n",
       "4        NaN    SUBARU  OUTBACK  ...             NaN              NaN   \n",
       "\n",
       "  TOTAL_VEHICLE_LENGTH AXLE_CNT VEHICLE_CONFIG CARGO_BODY_TYPE LOAD_TYPE  \\\n",
       "0                  NaN      NaN            NaN             NaN       NaN   \n",
       "1                  NaN      NaN            NaN             NaN       NaN   \n",
       "2                  NaN      NaN            NaN             NaN       NaN   \n",
       "3                  NaN      NaN            NaN             NaN       NaN   \n",
       "4                  NaN      NaN            NaN             NaN       NaN   \n",
       "\n",
       "  HAZMAT_OUT_OF_SERVICE_I MCS_OUT_OF_SERVICE_I  HAZMAT_CLASS  \n",
       "0                     NaN                  NaN           NaN  \n",
       "1                     NaN                  NaN           NaN  \n",
       "2                     NaN                  NaN           NaN  \n",
       "3                     NaN                  NaN           NaN  \n",
       "4                     NaN                  NaN           NaN  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1cabf",
   "metadata": {},
   "source": [
    "#### 2.3.2 Understand Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b672744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1838822 entries, 0 to 1838821\n",
      "Data columns (total 71 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   CRASH_UNIT_ID             int64  \n",
      " 1   CRASH_RECORD_ID           object \n",
      " 2   CRASH_DATE                object \n",
      " 3   UNIT_NO                   int64  \n",
      " 4   UNIT_TYPE                 object \n",
      " 5   NUM_PASSENGERS            float64\n",
      " 6   VEHICLE_ID                float64\n",
      " 7   CMRC_VEH_I                object \n",
      " 8   MAKE                      object \n",
      " 9   MODEL                     object \n",
      " 10  LIC_PLATE_STATE           object \n",
      " 11  VEHICLE_YEAR              float64\n",
      " 12  VEHICLE_DEFECT            object \n",
      " 13  VEHICLE_TYPE              object \n",
      " 14  VEHICLE_USE               object \n",
      " 15  TRAVEL_DIRECTION          object \n",
      " 16  MANEUVER                  object \n",
      " 17  TOWED_I                   object \n",
      " 18  FIRE_I                    object \n",
      " 19  OCCUPANT_CNT              float64\n",
      " 20  EXCEED_SPEED_LIMIT_I      object \n",
      " 21  TOWED_BY                  object \n",
      " 22  TOWED_TO                  object \n",
      " 23  AREA_00_I                 object \n",
      " 24  AREA_01_I                 object \n",
      " 25  AREA_02_I                 object \n",
      " 26  AREA_03_I                 object \n",
      " 27  AREA_04_I                 object \n",
      " 28  AREA_05_I                 object \n",
      " 29  AREA_06_I                 object \n",
      " 30  AREA_07_I                 object \n",
      " 31  AREA_08_I                 object \n",
      " 32  AREA_09_I                 object \n",
      " 33  AREA_10_I                 object \n",
      " 34  AREA_11_I                 object \n",
      " 35  AREA_12_I                 object \n",
      " 36  AREA_99_I                 object \n",
      " 37  FIRST_CONTACT_POINT       object \n",
      " 38  CMV_ID                    float64\n",
      " 39  USDOT_NO                  object \n",
      " 40  CCMC_NO                   object \n",
      " 41  ILCC_NO                   object \n",
      " 42  COMMERCIAL_SRC            object \n",
      " 43  GVWR                      object \n",
      " 44  CARRIER_NAME              object \n",
      " 45  CARRIER_STATE             object \n",
      " 46  CARRIER_CITY              object \n",
      " 47  HAZMAT_PLACARDS_I         object \n",
      " 48  HAZMAT_NAME               object \n",
      " 49  UN_NO                     object \n",
      " 50  HAZMAT_PRESENT_I          object \n",
      " 51  HAZMAT_REPORT_I           object \n",
      " 52  HAZMAT_REPORT_NO          object \n",
      " 53  MCS_REPORT_I              object \n",
      " 54  MCS_REPORT_NO             object \n",
      " 55  HAZMAT_VIO_CAUSE_CRASH_I  object \n",
      " 56  MCS_VIO_CAUSE_CRASH_I     object \n",
      " 57  IDOT_PERMIT_NO            object \n",
      " 58  WIDE_LOAD_I               object \n",
      " 59  TRAILER1_WIDTH            object \n",
      " 60  TRAILER2_WIDTH            object \n",
      " 61  TRAILER1_LENGTH           float64\n",
      " 62  TRAILER2_LENGTH           float64\n",
      " 63  TOTAL_VEHICLE_LENGTH      float64\n",
      " 64  AXLE_CNT                  float64\n",
      " 65  VEHICLE_CONFIG            object \n",
      " 66  CARGO_BODY_TYPE           object \n",
      " 67  LOAD_TYPE                 object \n",
      " 68  HAZMAT_OUT_OF_SERVICE_I   object \n",
      " 69  MCS_OUT_OF_SERVICE_I      object \n",
      " 70  HAZMAT_CLASS              object \n",
      "dtypes: float64(9), int64(2), object(60)\n",
      "memory usage: 996.1+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicles_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4978ea",
   "metadata": {},
   "source": [
    "#### 2.3.3 Format Feature names and Row Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9207f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_df.columns = vehicles_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf8fd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string values in object columns to lowercase\n",
    "for col in vehicles_df.select_dtypes(include='object').columns:\n",
    "    vehicles_df[col] = vehicles_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18b198",
   "metadata": {},
   "source": [
    "#### 2.3.4 Drop features with overly high null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a50afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cmrc_veh_i',\n",
       " 'fire_i',\n",
       " 'exceed_speed_limit_i',\n",
       " 'towed_by',\n",
       " 'towed_to',\n",
       " 'area_00_i',\n",
       " 'area_03_i',\n",
       " 'area_04_i',\n",
       " 'area_09_i',\n",
       " 'cmv_id',\n",
       " 'usdot_no',\n",
       " 'ccmc_no',\n",
       " 'ilcc_no',\n",
       " 'commercial_src',\n",
       " 'gvwr',\n",
       " 'carrier_name',\n",
       " 'carrier_state',\n",
       " 'carrier_city',\n",
       " 'hazmat_placards_i',\n",
       " 'hazmat_name',\n",
       " 'un_no',\n",
       " 'hazmat_present_i',\n",
       " 'hazmat_report_i',\n",
       " 'hazmat_report_no',\n",
       " 'mcs_report_i',\n",
       " 'mcs_report_no',\n",
       " 'hazmat_vio_cause_crash_i',\n",
       " 'mcs_vio_cause_crash_i',\n",
       " 'idot_permit_no',\n",
       " 'wide_load_i',\n",
       " 'trailer1_width',\n",
       " 'trailer2_width',\n",
       " 'trailer1_length',\n",
       " 'trailer2_length',\n",
       " 'total_vehicle_length',\n",
       " 'axle_cnt',\n",
       " 'vehicle_config',\n",
       " 'cargo_body_type',\n",
       " 'load_type',\n",
       " 'hazmat_out_of_service_i',\n",
       " 'mcs_out_of_service_i',\n",
       " 'hazmat_class']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of all features with 90% or more of its values are null\n",
    "high_null_features = list(vehicles_df.columns[(vehicles_df.isna().sum() / len(vehicles_df) * 100) >= 90])\n",
    "high_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7afb2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_cleaned = vehicles_df.drop(columns=high_null_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7697412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_unit_id</th>\n",
       "      <th>crash_record_id</th>\n",
       "      <th>crash_date</th>\n",
       "      <th>unit_no</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>num_passengers</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>lic_plate_state</th>\n",
       "      <th>...</th>\n",
       "      <th>area_02_i</th>\n",
       "      <th>area_05_i</th>\n",
       "      <th>area_06_i</th>\n",
       "      <th>area_07_i</th>\n",
       "      <th>area_08_i</th>\n",
       "      <th>area_10_i</th>\n",
       "      <th>area_11_i</th>\n",
       "      <th>area_12_i</th>\n",
       "      <th>area_99_i</th>\n",
       "      <th>first_contact_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [crash_unit_id, crash_record_id, crash_date, unit_no, unit_type, num_passengers, vehicle_id, make, model, lic_plate_state, vehicle_year, vehicle_defect, vehicle_type, vehicle_use, travel_direction, maneuver, towed_i, occupant_cnt, area_01_i, area_02_i, area_05_i, area_06_i, area_07_i, area_08_i, area_10_i, area_11_i, area_12_i, area_99_i, first_contact_point]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates based on crash_unit_id, crash_record_id, and vehicle_id\n",
    "vehicles_cleaned[vehicles_cleaned.duplicated(subset=['crash_unit_id', 'crash_record_id', 'vehicle_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f53138",
   "metadata": {},
   "source": [
    "The output tells us that there are no duplicate rows in the vehicles_cleaned DataFrame based on the specified subset of columns: crash_unit_id, crash_record_id, and vehicle_id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48baa70e",
   "metadata": {},
   "source": [
    "#### 2.3.5 deleting vehicles dataset from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "af9ca0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes the vehicle_df dataframe to clear up memory\n",
    "\n",
    "del vehicles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9eb17f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af6c7ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     192482\n",
       "2.0      50351\n",
       "3.0      19667\n",
       "4.0       6490\n",
       "5.0       1745\n",
       "6.0        699\n",
       "7.0        259\n",
       "8.0        121\n",
       "10.0        80\n",
       "9.0         72\n",
       "11.0        46\n",
       "12.0        40\n",
       "14.0        22\n",
       "15.0        18\n",
       "13.0        17\n",
       "17.0        13\n",
       "19.0        11\n",
       "18.0        10\n",
       "16.0         9\n",
       "27.0         8\n",
       "24.0         6\n",
       "26.0         6\n",
       "20.0         5\n",
       "28.0         5\n",
       "43.0         4\n",
       "35.0         4\n",
       "29.0         4\n",
       "40.0         4\n",
       "25.0         4\n",
       "21.0         4\n",
       "34.0         4\n",
       "32.0         3\n",
       "22.0         3\n",
       "42.0         2\n",
       "33.0         2\n",
       "46.0         2\n",
       "36.0         2\n",
       "23.0         2\n",
       "38.0         2\n",
       "30.0         2\n",
       "31.0         1\n",
       "59.0         1\n",
       "37.0         1\n",
       "52.0         1\n",
       "Name: num_passengers, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['num_passengers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf637b9",
   "metadata": {},
   "source": [
    "This is redundant information. This information does not include the driver, but this information is captured in occupant count. will drop this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "926a58f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          905826\n",
       "2          853710\n",
       "3           61407\n",
       "4           12627\n",
       "5            3368\n",
       "6            1058\n",
       "7             404\n",
       "8             177\n",
       "9              82\n",
       "10             43\n",
       "0              37\n",
       "11             23\n",
       "12             15\n",
       "13             10\n",
       "14              9\n",
       "15              8\n",
       "16              7\n",
       "17              5\n",
       "18              5\n",
       "3778035         1\n",
       "Name: unit_no, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['unit_no'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a48a2",
   "metadata": {},
   "source": [
    "This is aftermath. unhelpful. remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e98fe0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driver                 1539401\n",
       "parked                  242214\n",
       "pedestrian               23417\n",
       "bicycle                  14716\n",
       "driverless               14540\n",
       "non-motor vehicle         1665\n",
       "non-contact vehicle        327\n",
       "disabled vehicle           280\n",
       "equestrian                   8\n",
       "Name: unit_type, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['unit_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f6674",
   "metadata": {},
   "source": [
    "Most of the values are drivers or parked cars. this will not be useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f743e8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chevrolet                                                    207108\n",
       "ford                                                         179385\n",
       "unknown                                                      178486\n",
       "nissan                                                       144424\n",
       "honda                                                        132729\n",
       "                                                              ...  \n",
       "columbia                                                          1\n",
       "medical coaches, inc.                                             1\n",
       "middlebury(mfd. by coachman homes, div.of coachmen                1\n",
       "warrenville trailer manufacturing, inc. (warrenville, il)         1\n",
       "maverick                                                          1\n",
       "Name: make, Length: 1394, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['make'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27a37b",
   "metadata": {},
   "source": [
    "high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e5bd4212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown                                      180803\n",
       "other (explain in narrative)                 174151\n",
       "camry                                         57164\n",
       "corolla                                       36302\n",
       "civic                                         34455\n",
       "                                              ...  \n",
       "new paris traveler corp., new paris, ind.         1\n",
       "mikasa                                            1\n",
       "bertolini container co.                           1\n",
       "mulsanne                                          1\n",
       "808 series                                        1\n",
       "Name: model, Length: 2643, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2c692",
   "metadata": {},
   "source": [
    "This feels like it could be helpful, but many unknowns and 'other', and very high cardinality. The important information that we'd gain from this is already included in vehicle_type. So we can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5d17549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none                958779\n",
       "unknown             817496\n",
       "other                10626\n",
       "brakes                5517\n",
       "tires                  900\n",
       "steering               814\n",
       "wheels                 449\n",
       "suspension             284\n",
       "fuel system            265\n",
       "engine/motor           231\n",
       "windows                116\n",
       "lights                 109\n",
       "cargo                   65\n",
       "signals                 42\n",
       "restraint system        27\n",
       "trailer coupling        25\n",
       "exhaust                 21\n",
       "Name: vehicle_defect, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['vehicle_defect'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ca711",
   "metadata": {},
   "source": [
    "Most of the values are none or unknown. This will not be particularly useful for analysis. can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a96f7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger                                 1126457\n",
       "sport utility vehicle (suv)                250398\n",
       "unknown/na                                 163775\n",
       "van/mini-van                                84122\n",
       "pickup                                      58998\n",
       "truck - single unit                         33685\n",
       "other                                       22103\n",
       "bus over 15 pass.                           19719\n",
       "tractor w/ semi-trailer                     16961\n",
       "bus up to 15 pass.                           5348\n",
       "motorcycle (over 150cc)                      4383\n",
       "single unit truck with trailer               3047\n",
       "other vehicle with trailer                   2456\n",
       "tractor w/o semi-trailer                     2233\n",
       "autocycle                                     680\n",
       "moped or motorized bicycle                    676\n",
       "motor driven cycle                            328\n",
       "all-terrain vehicle (atv)                     199\n",
       "farm equipment                                 87\n",
       "3-wheeled motorcycle (2 rear wheels)           73\n",
       "recreational off-highway vehicle (rov)         30\n",
       "snowmobile                                      8\n",
       "Name: vehicle_type, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['vehicle_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "818a2c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n          421689\n",
       "s          413205\n",
       "w          372992\n",
       "e          365800\n",
       "unknown    143678\n",
       "se          23025\n",
       "nw          21056\n",
       "sw          17411\n",
       "ne          16910\n",
       "Name: travel_direction, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['travel_direction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda2a1c",
   "metadata": {},
   "source": [
    "Unhelpful for analysis. Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5936c3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "straight ahead                        831882\n",
       "parked                                246368\n",
       "unknown/na                            136331\n",
       "slow/stop in traffic                  130774\n",
       "turning left                          107438\n",
       "backing                                72110\n",
       "turning right                          60105\n",
       "passing/overtaking                     43818\n",
       "changing lanes                         34383\n",
       "other                                  30275\n",
       "entering traffic lane from parking     21177\n",
       "merging                                12694\n",
       "u-turn                                 10318\n",
       "starting in traffic                    10011\n",
       "leaving traffic lane to park            8682\n",
       "avoiding vehicles/objects               7538\n",
       "skidding/control loss                   6585\n",
       "enter from drive/alley                  6313\n",
       "parked in traffic lane                  5547\n",
       "slow/stop - left turn                   3042\n",
       "driving wrong way                       2699\n",
       "negotiating a curve                     2167\n",
       "slow/stop - right turn                  1929\n",
       "slow/stop - load/unload                 1663\n",
       "turning on red                           682\n",
       "driverless                               673\n",
       "diverging                                282\n",
       "disabled                                 280\n",
       "Name: maneuver, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['maneuver'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725b2d3",
   "metadata": {},
   "source": [
    "This feature could be important as it has to do with what was happening prior to the crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d944cd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    215790\n",
       "n     12402\n",
       "Name: towed_i, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['towed_i'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a58a03",
   "metadata": {},
   "source": [
    "Aftermath; Unhelpful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "96ebf7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     1301432\n",
       "0.0      236967\n",
       "2.0      181570\n",
       "3.0       47614\n",
       "4.0       18898\n",
       "5.0        6204\n",
       "6.0        1649\n",
       "7.0         661\n",
       "8.0         249\n",
       "9.0         117\n",
       "11.0         75\n",
       "10.0         70\n",
       "12.0         44\n",
       "13.0         39\n",
       "15.0         20\n",
       "14.0         17\n",
       "16.0         16\n",
       "18.0         13\n",
       "20.0         12\n",
       "19.0         10\n",
       "17.0          8\n",
       "28.0          8\n",
       "25.0          6\n",
       "26.0          6\n",
       "36.0          5\n",
       "21.0          5\n",
       "29.0          5\n",
       "44.0          4\n",
       "27.0          4\n",
       "41.0          4\n",
       "35.0          4\n",
       "33.0          3\n",
       "23.0          3\n",
       "30.0          3\n",
       "22.0          3\n",
       "39.0          2\n",
       "31.0          2\n",
       "43.0          2\n",
       "34.0          2\n",
       "47.0          2\n",
       "99.0          2\n",
       "38.0          1\n",
       "37.0          1\n",
       "60.0          1\n",
       "24.0          1\n",
       "32.0          1\n",
       "53.0          1\n",
       "Name: occupant_cnt, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['occupant_cnt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15431ac",
   "metadata": {},
   "source": [
    "It is unclear what the area_##_i features represent. They will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7afd124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "front                 352490\n",
       "rear                  237180\n",
       "unknown               171216\n",
       "side-left             123853\n",
       "front-left-corner     120599\n",
       "front-right-corner    118087\n",
       "side-right            117983\n",
       "front-left             81524\n",
       "front-right            76903\n",
       "rear-left              68089\n",
       "rear-left-corner       53479\n",
       "other                  41867\n",
       "rear-right-corner      39230\n",
       "rear-right             36488\n",
       "side-left-rear         30569\n",
       "total (all areas)      28268\n",
       "side-right-rear        23168\n",
       "side-left-front        20132\n",
       "side-right-front       17338\n",
       "none                   14038\n",
       "roof                   11958\n",
       "under carriage          5900\n",
       "top                     2259\n",
       "Name: first_contact_point, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['first_contact_point'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99843a",
   "metadata": {},
   "source": [
    "This feature could indicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "987d4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_features_to_drop = ['num_passengers', \n",
    "                            'crash_unit_id',\n",
    "                            'crash_date',\n",
    "                            'unit_type',\n",
    "                            'make', \n",
    "                            'model',\n",
    "                            'vehicle_id',\n",
    "                           'vehicle_defect',\n",
    "                           'unit_no',\n",
    "                           'lic_plate_state',\n",
    "                            'vehicle_year',\n",
    "                           'vehicle_use',\n",
    "                           'travel_direction',\n",
    "                           'towed_i',\n",
    "                            'area_01_i',\n",
    "                           'area_02_i', \n",
    "                            'area_05_i',\n",
    "                            'area_06_i',\n",
    "                            'area_07_i',\n",
    "                            'area_08_i',\n",
    "                            'area_10_i',\n",
    "                            'area_11_i',\n",
    "                            'area_12_i',\n",
    "                            'area_99_i', \n",
    "                           'first_contact_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3e693513",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_cleaned = vehicles_cleaned.drop(columns=vehicle_features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5471682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1838822 entries, 0 to 1838821\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   crash_record_id  object \n",
      " 1   vehicle_type     object \n",
      " 2   maneuver         object \n",
      " 3   occupant_cnt     float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 56.1+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicles_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f60a9f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crash_record_id', 'vehicle_type', 'maneuver', 'occupant_cnt']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vehicles_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cae42ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Passenger Vehicles                   1210579\n",
       "SUVs                                  250398\n",
       "Trucks                                114924\n",
       "Buses                                  25067\n",
       "Other                                  24559\n",
       "Motorcycles                             6140\n",
       "Recreational/Off-Highway Vehicles        237\n",
       "Farm and Specialized Equipment            87\n",
       "Name: vehicle_category, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map the original vehicle types to more specific categories\n",
    "vehicle_type_mapping = {\n",
    "    'passenger': 'Passenger Vehicles',\n",
    "    'sport utility vehicle (suv)': 'SUVs',\n",
    "    'van/mini-van': 'Passenger Vehicles',\n",
    "    'pickup': 'Trucks',\n",
    "    'truck - single unit': 'Trucks',\n",
    "    'single unit truck with trailer': 'Trucks',\n",
    "    'other': 'Other',\n",
    "    'bus over 15 pass.': 'Buses',\n",
    "    'bus up to 15 pass.': 'Buses',\n",
    "    'tractor w/ semi-trailer': 'Trucks',\n",
    "    'tractor w/o semi-trailer': 'Trucks',\n",
    "    'motorcycle (over 150cc)': 'Motorcycles',\n",
    "    'other vehicle with trailer': 'Other',\n",
    "    'autocycle': 'Motorcycles',\n",
    "    'moped or motorized bicycle': 'Motorcycles',\n",
    "    'motor driven cycle': 'Motorcycles',\n",
    "    'all-terrain vehicle (atv)': 'Recreational/Off-Highway Vehicles',\n",
    "    'farm equipment': 'Farm and Specialized Equipment',\n",
    "    '3-wheeled motorcycle (2 rear wheels)': 'Motorcycles',\n",
    "    'recreational off-highway vehicle (rov)': 'Recreational/Off-Highway Vehicles',\n",
    "    'snowmobile': 'Recreational/Off-Highway Vehicles',\n",
    "    'unknown/na': np.nan  # Set 'unknown/na' to NaN\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'vehicle_type' column\n",
    "vehicles_cleaned['vehicle_category'] = vehicles_cleaned['vehicle_type'].map(vehicle_type_mapping)\n",
    "\n",
    "# Check the value counts for the new grouped categories\n",
    "vehicles_cleaned['vehicle_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f7db7e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Passenger Vehicles    1210579\n",
       "SUVs                   250398\n",
       "Trucks                 114924\n",
       "Buses                   25067\n",
       "Other                   24559\n",
       "Motorcycles              6140\n",
       "Name: vehicle_category, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows with 'Recreational/Off-Highway Vehicles' and 'Farm and Specialized Equipment'\n",
    "vehicles_cleaned = vehicles_cleaned[~vehicles_cleaned['vehicle_category'].isin(['Recreational/Off-Highway Vehicles', 'Farm and Specialized Equipment'])]\n",
    "\n",
    "# Check the value counts after removing those categories\n",
    "vehicles_cleaned['vehicle_category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8b1f1a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1838498 entries, 0 to 1838821\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   crash_record_id   object \n",
      " 1   vehicle_type      object \n",
      " 2   maneuver          object \n",
      " 3   occupant_cnt      float64\n",
      " 4   vehicle_category  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 84.2+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicles_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fba39bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard Movement               1006307\n",
       "Reversing/Stopping               364590\n",
       "Turn/Change of Direction         212901\n",
       "Special Cases                     34191\n",
       "Avoidance/Emergency Response      16282\n",
       "Name: maneuver_category, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify the maneuver mapping to treat 'unknown/na' as NaN\n",
    "maneuver_mapping = {\n",
    "    'straight ahead': 'Standard Movement',\n",
    "    'slow/stop in traffic': 'Standard Movement',\n",
    "    'passing/overtaking': 'Standard Movement',\n",
    "    'unknown/na': np.nan,  # Set 'unknown/na' to NaN\n",
    "    \n",
    "    'parked': 'Reversing/Stopping',\n",
    "    'entering traffic lane from parking': 'Reversing/Stopping',\n",
    "    'starting in traffic': 'Reversing/Stopping',\n",
    "    \n",
    "    'turning left': 'Turn/Change of Direction',\n",
    "    'turning right': 'Turn/Change of Direction',\n",
    "    'u-turn': 'Turn/Change of Direction',\n",
    "    'changing lanes': 'Turn/Change of Direction',\n",
    "    'turning on red': 'Turn/Change of Direction',\n",
    "    \n",
    "    'backing': 'Reversing/Stopping',\n",
    "    'avoiding vehicles/objects': 'Avoidance/Emergency Response',\n",
    "    'skidding/control loss': 'Avoidance/Emergency Response',\n",
    "    'negotiating a curve': 'Avoidance/Emergency Response',\n",
    "    \n",
    "    'leaving traffic lane to park': 'Reversing/Stopping',\n",
    "    'enter from drive/alley': 'Reversing/Stopping',\n",
    "    \n",
    "    'driving wrong way': 'Special Cases',\n",
    "    'diverging': 'Special Cases',\n",
    "    'driverless': 'Special Cases',\n",
    "    'disabled': 'Special Cases',\n",
    "    \n",
    "    'other': 'Special Cases',\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'maneuver' column\n",
    "vehicles_cleaned['maneuver_category'] = vehicles_cleaned['maneuver'].map(maneuver_mapping)\n",
    "\n",
    "# Check the value counts for the new 'maneuver_category'\n",
    "vehicles_cleaned['maneuver_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f31b428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single Occupancy    248056\n",
       "Small Group           8763\n",
       "Medium Group           429\n",
       "Large Group             91\n",
       "Very Large Group         0\n",
       "Name: occupant_category, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 0, 99, and negative values with NaN in 'occupant_cnt' for future dropping\n",
    "vehicles_cleaned['occupant_cnt'] = vehicles_cleaned['occupant_cnt'].replace([0, 99], np.nan)\n",
    "\n",
    "# Define bins for the categories (including the 20-98 range for Very Large Group)\n",
    "bins = [1, 4, 8, 19, 98, float('inf')]  # Adjusted to include 20-98 for Very Large Group\n",
    "labels = ['Single Occupancy', 'Small Group', 'Medium Group', 'Large Group', 'Very Large Group']  # 5 labels for 5 bins\n",
    "\n",
    "# Use pd.cut to categorize the 'occupant_cnt' column based on the bins\n",
    "vehicles_cleaned['occupant_category'] = pd.cut(\n",
    "    vehicles_cleaned['occupant_cnt'], \n",
    "    bins=bins, \n",
    "    labels=labels, \n",
    "    right=True, \n",
    "    include_lowest=False  # Exclude 0 from Single Occupancy\n",
    ")\n",
    "\n",
    "# Handle the NaN values for 'occupant_category' (those rows with invalid occupant_cnt, such as 0 or 99)\n",
    "vehicles_cleaned['occupant_category'] = vehicles_cleaned['occupant_category'].where(\n",
    "    vehicles_cleaned['occupant_category'].notna(), np.nan\n",
    ")\n",
    "\n",
    "# Check the categories to ensure the correct label reclassification\n",
    "vehicles_cleaned['occupant_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0cc4588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single Occupancy    248056\n",
       "Small Group           8763\n",
       "Medium Group           429\n",
       "Large Group             91\n",
       "Name: occupant_category, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove 'Very Large Group' rows since it contains zero values\n",
    "vehicles_cleaned = vehicles_cleaned[vehicles_cleaned['occupant_category'] != 'Very Large Group']\n",
    "\n",
    "# Drop 'Very Large Group' from the categorical data if it still exists\n",
    "vehicles_cleaned['occupant_category'] = vehicles_cleaned['occupant_category'].cat.remove_categories('Very Large Group')\n",
    "\n",
    "# Check the categories to ensure the correct label reclassification\n",
    "vehicles_cleaned['occupant_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "916b7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1838498 entries, 0 to 1838821\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Dtype   \n",
      "---  ------             -----   \n",
      " 0   crash_record_id    object  \n",
      " 1   vehicle_type       object  \n",
      " 2   maneuver           object  \n",
      " 3   occupant_cnt       float64 \n",
      " 4   vehicle_category   object  \n",
      " 5   maneuver_category  object  \n",
      " 6   occupant_category  category\n",
      "dtypes: category(1), float64(1), object(5)\n",
      "memory usage: 99.9+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicles_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "81b873a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id            0\n",
       "vehicle_type           43056\n",
       "maneuver               43056\n",
       "occupant_cnt          279977\n",
       "vehicle_category      206831\n",
       "maneuver_category     204227\n",
       "occupant_category    1581159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "541d86c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279977"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['occupant_cnt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aab63867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     1301182\n",
       "2.0      181549\n",
       "3.0       47609\n",
       "4.0       18898\n",
       "5.0        6204\n",
       "6.0        1649\n",
       "7.0         661\n",
       "8.0         249\n",
       "9.0         117\n",
       "11.0         75\n",
       "10.0         70\n",
       "12.0         44\n",
       "13.0         39\n",
       "15.0         20\n",
       "14.0         17\n",
       "16.0         16\n",
       "18.0         13\n",
       "20.0         12\n",
       "19.0         10\n",
       "17.0          8\n",
       "28.0          8\n",
       "25.0          6\n",
       "26.0          6\n",
       "21.0          5\n",
       "29.0          5\n",
       "36.0          5\n",
       "27.0          4\n",
       "41.0          4\n",
       "35.0          4\n",
       "44.0          4\n",
       "30.0          3\n",
       "33.0          3\n",
       "23.0          3\n",
       "22.0          3\n",
       "43.0          2\n",
       "39.0          2\n",
       "34.0          2\n",
       "47.0          2\n",
       "31.0          2\n",
       "38.0          1\n",
       "37.0          1\n",
       "60.0          1\n",
       "24.0          1\n",
       "32.0          1\n",
       "53.0          1\n",
       "Name: occupant_cnt, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned['occupant_cnt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "75199ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'occupant_category' and 'occupant_cnt' column\n",
    "vehicles_cleaned = vehicles_cleaned.drop(columns=['occupant_category', 'occupant_cnt', 'vehicle_type', 'maneuver'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8b0b81bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id           0\n",
       "vehicle_category     206831\n",
       "maneuver_category    204227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6401012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any null (NaN) values\n",
    "vehicles_cleaned = vehicles_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6cdc0eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1555406 entries, 1 to 1838821\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   crash_record_id    1555406 non-null  object\n",
      " 1   vehicle_category   1555406 non-null  object\n",
      " 2   maneuver_category  1555406 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 47.5+ MB\n"
     ]
    }
   ],
   "source": [
    "vehicles_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e40a2b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id      0\n",
       "vehicle_category     0\n",
       "maneuver_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c1dee",
   "metadata": {},
   "source": [
    "### Merging `crashes_cleaned`, `people_cleaned`, & `vehicles_cleaned`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe87de2",
   "metadata": {},
   "source": [
    "Relationships Between Tables and Justification for Merging\n",
    "\n",
    "1. Relationship Between crashes_cleaned and people_cleaned\n",
    "\t•\tcrash_record_id is the primary key in crashes_cleaned and appears in people_cleaned.\n",
    "\t•\tEach crash in crashes_cleaned can involve multiple people (drivers, passengers, pedestrians).\n",
    "\n",
    "This means the relationship is:\n",
    "\t•\tOne-to-Many: One crash (crashes_cleaned) can have many people (people_cleaned) associated with it.\n",
    "\n",
    "2. Relationship Between crashes_cleaned and vehicles_cleaned\n",
    "\t•\tcrash_record_id is the primary key in crashes_cleaned and appears in vehicles_cleaned.\n",
    "\t•\tEach crash in crashes_cleaned can involve multiple vehicles.\n",
    "\n",
    "This means the relationship is:\n",
    "\t•\tOne-to-Many: One crash (crashes_cleaned) can have many vehicles (vehicles_cleaned) associated with it.\n",
    "\n",
    "3. Relationship Between people_cleaned and vehicles_cleaned\n",
    "\t•\tBoth tables are linked via crash_record_id, but they describe different entities.\n",
    "\t•\tPeople (people_cleaned) and vehicles (vehicles_cleaned) may not have a direct relationship unless there’s another shared identifier (e.g., vehicle_id or person_id).\n",
    "\n",
    "This means the relationship is:\n",
    "\t•\tMany-to-Many: Many people can be in many vehicles within the same crash. (However, this relationship is indirectly expressed through crash_record_id.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d71642",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f56dd5",
   "metadata": {},
   "source": [
    "The goal of aggregating the people_cleaned dataset is to handle the many-to-one relationship between the people_cleaned and crashes_cleaned datasets. Each crash_record_id in crashes_cleaned may have multiple associated records in people_cleaned, as a single crash may involve multiple people. Since our focus is on predicting the severity of crashes using the severity_category (the target variable in crashes_cleaned), we need to aggregate the people data to ensure each crash record has only one corresponding row of data.\n",
    "\n",
    "The aggregation process involves grouping the people_cleaned dataset by crash_record_id, which is the shared key between the two datasets. For features like sex, age_group, and airbag_deployed, we use the most frequent value for each crash. In cases where there is a tie (e.g., multiple values with the same frequency), we resolve the tie by selecting the value with the highest count using the idxmax() function on the value counts of each group. This ensures consistency and avoids ambiguity in cases of a tie.\n",
    "\n",
    "Similarly, the vehicles_cleaned dataset also has a many-to-one relationship with crashes_cleaned, where each crash_record_id in crashes_cleaned can have multiple associated vehicle records. As with the people_cleaned data, we need to aggregate the vehicle data to ensure that each crash record has a corresponding single row. The aggregation will allow us to focus on features like vehicle_category and other vehicle-specific attributes that might affect crash severity.\n",
    "\n",
    "By grouping the vehicles_cleaned dataset by crash_record_id, we can apply the same aggregation logic as with the people data. This ensures that we retain the most important vehicle-specific features while also maintaining a consistent one-to-one relationship between crashes_cleaned and the aggregated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "de8ebef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 299.10 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_record_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>airbag_deployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000013b0123279411e0ec856dae95ab9f0851764350b7f...</td>\n",
       "      <td>female</td>\n",
       "      <td>27-65</td>\n",
       "      <td>Not Deployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002c0771fb6f2c70ba775b7f6b501608cadea85c1dd1...</td>\n",
       "      <td>female</td>\n",
       "      <td>27-65</td>\n",
       "      <td>Not Deployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00005696946846c8b8a1d378dba4e2a5ed84a9b2876fe0...</td>\n",
       "      <td>male</td>\n",
       "      <td>27-65</td>\n",
       "      <td>Not Deployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000070ed7a6357c3298f5edc6fb7d5ce925a10f46660f3...</td>\n",
       "      <td>male</td>\n",
       "      <td>27-65</td>\n",
       "      <td>Not Deployed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c280b9c15e9ec96aa2eed34bf0f3ef1d604c6ea460...</td>\n",
       "      <td>female</td>\n",
       "      <td>27-65</td>\n",
       "      <td>Not Deployed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     crash_record_id     sex age_group  \\\n",
       "0  000013b0123279411e0ec856dae95ab9f0851764350b7f...  female     27-65   \n",
       "1  00002c0771fb6f2c70ba775b7f6b501608cadea85c1dd1...  female     27-65   \n",
       "2  00005696946846c8b8a1d378dba4e2a5ed84a9b2876fe0...    male     27-65   \n",
       "3  000070ed7a6357c3298f5edc6fb7d5ce925a10f46660f3...    male     27-65   \n",
       "4  0000c280b9c15e9ec96aa2eed34bf0f3ef1d604c6ea460...  female     27-65   \n",
       "\n",
       "  airbag_deployed  \n",
       "0    Not Deployed  \n",
       "1    Not Deployed  \n",
       "2    Not Deployed  \n",
       "3    Not Deployed  \n",
       "4    Not Deployed  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform a single groupby and aggregate all columns at once\n",
    "people_aggregated = (\n",
    "    people_cleaned.groupby('crash_record_id').agg({\n",
    "        'sex': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan,\n",
    "        'age_group': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan,\n",
    "        'airbag_deployed': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "    }).reset_index()\n",
    ")\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Previews the aggregated results\n",
    "people_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cc78e",
   "metadata": {},
   "source": [
    "Large Data Processing:\n",
    "\n",
    "* If you’re working with large datasets (e.g., in data science or machine learning) and have explicitly deleted variables (e.g., using del) but still notice high memory usage, calling gc.collect() ensures the unused memory is released.\n",
    "    \n",
    "Long-Running Programs:\n",
    "\n",
    "* For applications that run continuously (like servers or data pipelines), invoking gc.collect() at specific intervals can help manage memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "24c09970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deletes the people_cleaned dataframe to clear up memory\n",
    "del people_cleaned\n",
    "\n",
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "515f0b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 269.39 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_record_id</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>maneuver_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000013b0123279411e0ec856dae95ab9f0851764350b7f...</td>\n",
       "      <td>Passenger Vehicles</td>\n",
       "      <td>Reversing/Stopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002c0771fb6f2c70ba775b7f6b501608cadea85c1dd1...</td>\n",
       "      <td>Passenger Vehicles</td>\n",
       "      <td>Standard Movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00005696946846c8b8a1d378dba4e2a5ed84a9b2876fe0...</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>Reversing/Stopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000070ed7a6357c3298f5edc6fb7d5ce925a10f46660f3...</td>\n",
       "      <td>Passenger Vehicles</td>\n",
       "      <td>Standard Movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000b70a00c8809f76b5234f81753264d9160c314cc5e6...</td>\n",
       "      <td>Passenger Vehicles</td>\n",
       "      <td>Reversing/Stopping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     crash_record_id    vehicle_category  \\\n",
       "0  000013b0123279411e0ec856dae95ab9f0851764350b7f...  Passenger Vehicles   \n",
       "1  00002c0771fb6f2c70ba775b7f6b501608cadea85c1dd1...  Passenger Vehicles   \n",
       "2  00005696946846c8b8a1d378dba4e2a5ed84a9b2876fe0...              Trucks   \n",
       "3  000070ed7a6357c3298f5edc6fb7d5ce925a10f46660f3...  Passenger Vehicles   \n",
       "4  0000b70a00c8809f76b5234f81753264d9160c314cc5e6...  Passenger Vehicles   \n",
       "\n",
       "    maneuver_category  \n",
       "0  Reversing/Stopping  \n",
       "1   Standard Movement  \n",
       "2  Reversing/Stopping  \n",
       "3   Standard Movement  \n",
       "4  Reversing/Stopping  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Aggregating the vehicles data by crash_record_id\n",
    "vehicles_aggregated = vehicles_cleaned.groupby('crash_record_id').agg({\n",
    "    'vehicle_category': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan,  # Select the first mode\n",
    "    'maneuver_category': lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan   # Select the first mode\n",
    "}).reset_index()\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# View the aggregated vehicles data\n",
    "vehicles_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c0456ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deletes the vehicles_cleaned dataframe to clear up memory\n",
    "del vehicles_cleaned\n",
    "\n",
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cf5acb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes using an inner join\n",
    "merged_df = crashes_cleaned.merge(people_aggregated, on='crash_record_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2d6aa80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deletes the crashes_cleaned dataframe to clear up memory\n",
    "del crashes_cleaned\n",
    "\n",
    "# Perform garbage collection to free up memory by releasing unreferenced objects\n",
    "# This helps to manage memory usage, especially when working with large datasets or memory-intensive operations.\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e231d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(vehicles_aggregated, on='crash_record_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "42950479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 705346 entries, 0 to 705345\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   crash_record_id           705346 non-null  object  \n",
      " 1   lighting_condition        705346 non-null  category\n",
      " 2   roadway_surface_cond      705346 non-null  category\n",
      " 3   speed_limit_category      705346 non-null  category\n",
      " 4   traffic_control_category  705346 non-null  category\n",
      " 5   road_category             705346 non-null  category\n",
      " 6   severity_category         705346 non-null  category\n",
      " 7   crash_cause_category      705346 non-null  category\n",
      " 8   time_of_day               705346 non-null  category\n",
      " 9   day_of_week               705346 non-null  category\n",
      " 10  season                    705346 non-null  category\n",
      " 11  sex                       705346 non-null  object  \n",
      " 12  age_group                 705346 non-null  object  \n",
      " 13  airbag_deployed           705346 non-null  object  \n",
      " 14  vehicle_category          705346 non-null  object  \n",
      " 15  maneuver_category         705346 non-null  object  \n",
      "dtypes: category(10), object(6)\n",
      "memory usage: 44.4+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "72404fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the columns (except 'crash_record_id') to category type\n",
    "merged_df[[col for col in merged_df.columns if col != 'crash_record_id']] = merged_df[[col for col in merged_df.columns if col != 'crash_record_id']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "91b84967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id               object\n",
       "lighting_condition          category\n",
       "roadway_surface_cond        category\n",
       "speed_limit_category        category\n",
       "traffic_control_category    category\n",
       "road_category               category\n",
       "severity_category           category\n",
       "crash_cause_category        category\n",
       "time_of_day                 category\n",
       "day_of_week                 category\n",
       "season                      category\n",
       "sex                         category\n",
       "age_group                   category\n",
       "airbag_deployed             category\n",
       "vehicle_category            category\n",
       "maneuver_category           category\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the changes\n",
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7fb8c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns = merged_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c71a4f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string values in object columns to lowercase\n",
    "for col in merged_df.select_dtypes(include='object').columns:\n",
    "    merged_df[col] = merged_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "417c0be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id             0\n",
       "lighting_condition          0\n",
       "roadway_surface_cond        0\n",
       "speed_limit_category        0\n",
       "traffic_control_category    0\n",
       "road_category               0\n",
       "severity_category           0\n",
       "crash_cause_category        0\n",
       "time_of_day                 0\n",
       "day_of_week                 0\n",
       "season                      0\n",
       "sex                         0\n",
       "age_group                   0\n",
       "airbag_deployed             0\n",
       "vehicle_category            0\n",
       "maneuver_category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result\n",
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3a1d016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-serious    692193\n",
       "Serious         13153\n",
       "Name: severity_category, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['severity_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7237505a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_record_id</th>\n",
       "      <th>lighting_condition</th>\n",
       "      <th>roadway_surface_cond</th>\n",
       "      <th>speed_limit_category</th>\n",
       "      <th>traffic_control_category</th>\n",
       "      <th>road_category</th>\n",
       "      <th>severity_category</th>\n",
       "      <th>crash_cause_category</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>airbag_deployed</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>maneuver_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [crash_record_id, lighting_condition, roadway_surface_cond, speed_limit_category, traffic_control_category, road_category, severity_category, crash_cause_category, time_of_day, day_of_week, season, sex, age_group, airbag_deployed, vehicle_category, maneuver_category]\n",
       "Index: []"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate crash_record_id values\n",
    "merged_df[merged_df.duplicated(subset='crash_record_id', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "12399bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for crash_record_id:\n",
      "6c1659069e9c6285a650e70d6f9b574ed5f64c12888479093dfeef179c0344ec6d2057eae224b5c0d5dfc278c0a237f8c22543f07fdef2e4a95a3849871c9345    1\n",
      "b1099e521b2895496fd1e07adf0a7a8e5951524324b46fc6f1bb55a7cdd91151d6333fef63913fdfe3e75cd4ba47c9e8aba1a54d3af37ce3db416a6e5cf584f8    1\n",
      "b108accb609c2d67307d0c8c8c7d76be4792faed6554abe99f3780468e738e7493f8ee9089239c632fe500868edeefe1859fc5b2820fb5be47986b67c91985a8    1\n",
      "b108c6a47e34dd63f88879fd045946d5a95c90cae2910b8aab3f26cbd958601fcdf779fbbca2bd13650741a81064e7d5d19c87a776db46b32b5b3104c6708e69    1\n",
      "b108cdbe0649a3def6b17541148bff1b8a3b5289ac888ae34c615e96c2e745ec79fe85bed2fb00953f34362e65d01d30dc0a6aa62c140d7b7f89ea2c79a8ea6a    1\n",
      "                                                                                                                                   ..\n",
      "559aa3a1f71ea855105d98432e7b25145eaef80df6e74f369827fa2ae563859454e044ee166f7c0b0a3e8180eebdb0a49c6bb7a90187bd1ea5ce1a021133ecca    1\n",
      "559aa4fee2087be0d8d2e17dafe864982fd79989e57830b857f7c63efca7fc7b33081c0494e193daa37ef20e7fbaf8ae714d2c200d51a4802f1f036a6fd1d2f7    1\n",
      "559ac53d19b04f5b633bb9276bd1c0164a0c784633e847ca079d3772764c5812b0aac20f0576cecc62be96c87056642c26cf2155ab03d2bdbaf51480c021975b    1\n",
      "559ae327760dd75f6ea9ec458bed50cfedad8594d91bf5238268564f04062711e37198ca5ffe005ce5463a731832ab8605600435ee8738d464aeaf88bcfd4771    1\n",
      "ddb7c68c829fa774fa13b1a8bda817c7f9094a660447231ea7707c0ae19c6fab186f192076fd892cd3ad94987bd515ca2833a011008823e65a3e2b7a53544757    1\n",
      "Name: crash_record_id, Length: 705346, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for lighting_condition:\n",
      "daylight                  475786\n",
      "darkness, lighted road    151680\n",
      "darkness                   29623\n",
      "dusk                       21079\n",
      "unknown                    15502\n",
      "dawn                       11676\n",
      "Name: lighting_condition, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for roadway_surface_cond:\n",
      "dry                531856\n",
      "wet                 98380\n",
      "unknown             46647\n",
      "snow or slush       21772\n",
      "ice                  4713\n",
      "other                1743\n",
      "sand, mud, dirt       235\n",
      "Name: roadway_surface_cond, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for speed_limit_category:\n",
      "Medium    591857\n",
      "Low       106919\n",
      "High        6570\n",
      "Name: speed_limit_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for traffic_control_category:\n",
      "Other               390691\n",
      "Signal              231417\n",
      "Sign                 81904\n",
      "Markings & Lanes      1334\n",
      "Name: traffic_control_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for road_category:\n",
      "unknown                     531993\n",
      "multi-lane bidirectional    118871\n",
      "intersection                 22435\n",
      "other                        13682\n",
      "multi-lane one way            9204\n",
      "single-lane one way           9161\n",
      "Name: road_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for severity_category:\n",
      "Non-serious    692193\n",
      "Serious         13153\n",
      "Name: severity_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for crash_cause_category:\n",
      "Aggressive/Reckless Driving          374047\n",
      "Unknown/Other                        259358\n",
      "Driver's Condition/Experience         43426\n",
      "Environmental and Road Conditions     17505\n",
      "Distraction                           11010\n",
      "Name: crash_cause_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for time_of_day:\n",
      "Afternoon        303485\n",
      "Morning          184234\n",
      "Night (Early)    162107\n",
      "Night (Late)      55520\n",
      "Name: time_of_day, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for day_of_week:\n",
      "Fri     116745\n",
      "Thur    103776\n",
      "Wed     102327\n",
      "Tues    102057\n",
      "Sat     101733\n",
      "Mon      96151\n",
      "Sun      82557\n",
      "Name: day_of_week, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for season:\n",
      "Fall      194462\n",
      "Summer    184167\n",
      "Spring    165500\n",
      "Winter    161217\n",
      "Name: season, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for sex:\n",
      "female    368096\n",
      "male      336850\n",
      "other        400\n",
      "Name: sex, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for age_group:\n",
      "27-65    458230\n",
      "16-26    196623\n",
      "65+       28783\n",
      "1-15      21710\n",
      "Name: age_group, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for airbag_deployed:\n",
      "Not Deployed    618365\n",
      "Deployed         62049\n",
      "Unknown          24932\n",
      "Name: airbag_deployed, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for vehicle_category:\n",
      "Passenger Vehicles    586643\n",
      "SUVs                   59231\n",
      "Buses                  20677\n",
      "Other                  17793\n",
      "Trucks                 16545\n",
      "Motorcycles             4457\n",
      "Name: vehicle_category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Value counts for maneuver_category:\n",
      "Standard Movement               486827\n",
      "Reversing/Stopping              147164\n",
      "Turn/Change of Direction         40861\n",
      "Special Cases                    18278\n",
      "Avoidance/Emergency Response     12216\n",
      "Name: maneuver_category, dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column in the DataFrame and print value counts for each feature\n",
    "for column in merged_df.columns:\n",
    "    print(f\"Value counts for {column}:\")\n",
    "    print(merged_df[column].value_counts())\n",
    "    print(\"-\" * 50)  # Optional separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "463d1007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_record_id             0\n",
       "lighting_condition          0\n",
       "roadway_surface_cond        0\n",
       "speed_limit_category        0\n",
       "traffic_control_category    0\n",
       "road_category               0\n",
       "severity_category           0\n",
       "crash_cause_category        0\n",
       "time_of_day                 0\n",
       "day_of_week                 0\n",
       "season                      0\n",
       "sex                         0\n",
       "age_group                   0\n",
       "airbag_deployed             0\n",
       "vehicle_category            0\n",
       "maneuver_category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "143a1b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 639462 entries, 0 to 705345\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   crash_record_id           639462 non-null  object  \n",
      " 1   lighting_condition        639462 non-null  category\n",
      " 2   roadway_surface_cond      639462 non-null  category\n",
      " 3   speed_limit_category      639462 non-null  category\n",
      " 4   traffic_control_category  639462 non-null  category\n",
      " 5   road_category             639462 non-null  category\n",
      " 6   severity_category         639462 non-null  category\n",
      " 7   crash_cause_category      639462 non-null  category\n",
      " 8   time_of_day               639462 non-null  category\n",
      " 9   day_of_week               639462 non-null  category\n",
      " 10  season                    639462 non-null  category\n",
      " 11  sex                       639462 non-null  category\n",
      " 12  age_group                 639462 non-null  category\n",
      " 13  airbag_deployed           639462 non-null  category\n",
      " 14  vehicle_category          639462 non-null  category\n",
      " 15  maneuver_category         639462 non-null  category\n",
      "dtypes: category(15), object(1)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# List of columns you want to clean\n",
    "columns_to_clean = ['airbag_deployed', 'roadway_surface_cond', 'lighting_condition']  # replace with your actual column names\n",
    "\n",
    "# Iterate over each column in the list\n",
    "for column in columns_to_clean:\n",
    "    # Check for unwanted values in the current column and remove rows\n",
    "    merged_df = merged_df[~merged_df[column].str.contains(\n",
    "        'unknown|not applicable|other object|unknown/other', case=False, na=False)]\n",
    "\n",
    "# Verify the changes\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "077c86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'crash_record_id' column from the merged dataframe\n",
    "merged_df = merged_df.drop('crash_record_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "28621de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639462, 15)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2bcdff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lighting_condition          0\n",
       "roadway_surface_cond        0\n",
       "speed_limit_category        0\n",
       "traffic_control_category    0\n",
       "road_category               0\n",
       "severity_category           0\n",
       "crash_cause_category        0\n",
       "time_of_day                 0\n",
       "day_of_week                 0\n",
       "season                      0\n",
       "sex                         0\n",
       "age_group                   0\n",
       "airbag_deployed             0\n",
       "vehicle_category            0\n",
       "maneuver_category           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a3661ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-serious    0.980882\n",
       "Serious        0.019118\n",
       "Name: severity_category, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['severity_category'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6779b5",
   "metadata": {},
   "source": [
    "From the above output, we see that the classes are greatly imbalanced. This will be something I will need to address during the modeling phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "637f0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping classes into two groups for binary classification: 0 and 1\n",
    "merged_df.severity_category.replace({\n",
    "    'Serious' : 1,\n",
    "    'Non-serious' : 0},\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ffa951",
   "metadata": {},
   "source": [
    "## Very large data so going to take a subset for the feature importances modeling portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ee000",
   "metadata": {},
   "source": [
    "Chose 10% sampling as this provided a subset of just under 50k records. This optimizes computational efficiency and memory storage, while also ensuring there is adequate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b6c7d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired sample size (e.g., 10% of the dataset)\n",
    "sample_size = 0.10 \n",
    "\n",
    "# Perform stratified sampling to retain class distribution\n",
    "crashes_finalized_df, _ = train_test_split(\n",
    "    merged_df, \n",
    "    test_size=1-sample_size,  # Retain only `sample_size` fraction\n",
    "    stratify=merged_df['severity_category'], \n",
    "    random_state=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "288b1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 63946 entries, 175763 to 154697\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   lighting_condition        63946 non-null  category\n",
      " 1   roadway_surface_cond      63946 non-null  category\n",
      " 2   speed_limit_category      63946 non-null  category\n",
      " 3   traffic_control_category  63946 non-null  category\n",
      " 4   road_category             63946 non-null  category\n",
      " 5   severity_category         63946 non-null  int64   \n",
      " 6   crash_cause_category      63946 non-null  category\n",
      " 7   time_of_day               63946 non-null  category\n",
      " 8   day_of_week               63946 non-null  category\n",
      " 9   season                    63946 non-null  category\n",
      " 10  sex                       63946 non-null  category\n",
      " 11  age_group                 63946 non-null  category\n",
      " 12  airbag_deployed           63946 non-null  category\n",
      " 13  vehicle_category          63946 non-null  category\n",
      " 14  maneuver_category         63946 non-null  category\n",
      "dtypes: category(14), int64(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "crashes_finalized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5b3cef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "0    0.980882\n",
      "1    0.019118\n",
      "Name: severity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Confirm the class distribution remains the same\n",
    "print(\"Original class distribution:\")\n",
    "print(merged_df['severity_category'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ece6243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled class distribution:\n",
      "0    0.98089\n",
      "1    0.01911\n",
      "Name: severity_category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSampled class distribution:\")\n",
    "print(crashes_finalized_df['severity_category'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760f4b3",
   "metadata": {},
   "source": [
    "## Exporting dataset to kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943b161",
   "metadata": {},
   "source": [
    "I save the cleaned dataframe as a csv and manually upload it to kaggle for use in the rest of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c9e22651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and finalized DataFrame to a CSV file in the 'data' directory\n",
    "crashes_finalized_df.to_csv('./data/crashes_finalized_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
